// Auto-generated by RemoteMedia SDK - DO NOT EDIT
// Run `npm run generate-types` to regenerate

// RuntimeData types (matches Rust enum)
export type RuntimeDataType = 'audio' | 'video' | 'json' | 'text' | 'binary' | 'tensor' | 'numpy' | 'control' | 'controlmessage';

export interface AudioData {
  samples: Float32Array;
  sampleRate: number;
  channels: number;
  streamId?: string;
}

export interface VideoData {
  pixelData: Uint8Array;
  width: number;
  height: number;
  format: 'yuv420p' | 'rgb24' | 'rgba32' | 'gray8';
  codec?: 'raw' | 'h264' | 'vp8' | 'vp9' | 'av1';
  frameNumber?: number;
  isKeyframe?: boolean;
}

export interface TensorData {
  data: Uint8Array;
  shape: number[];
  dtype: 'f32' | 'f16' | 'i32' | 'i8' | 'u8';
}

export interface NumpyArray {
  data: Uint8Array;
  shape: number[];
  dtype: string;
  strides: number[];
}

export interface ControlMessage {
  type: 'start' | 'stop' | 'cancel' | 'flush' | 'config_update' | 'custom';
  timestamp?: number;
  segmentId?: string;
  metadata?: Record<string, unknown>;
  cancelRange?: { start: number; end: number };
}

export type RuntimeData =
  | { type: 'audio'; data: AudioData }
  | { type: 'video'; data: VideoData }
  | { type: 'json'; data: Record<string, unknown> }
  | { type: 'text'; data: string }
  | { type: 'binary'; data: Uint8Array }
  | { type: 'tensor'; data: TensorData }
  | { type: 'numpy'; data: NumpyArray }
  | { type: 'control'; data: ControlMessage };

/** Resamples audio to target sample rate - Configuration */
export interface AudioResampleConfig {
  /** Target sample rate in Hz */
  target_sample_rate?: number;
}

/** Voice Activity Detection using Silero VAD model - Configuration */
export interface SileroVADConfig {
  /** Minimum silence duration in ms */
  min_silence_duration_ms?: number;
  /** Minimum speech duration in ms */
  min_speech_duration_ms?: number;
  /** Speech probability threshold */
  threshold?: number;
}

/** Collects text chunks into complete utterances - Configuration */
export interface TextCollectorConfig {
  /** Delimiter to split on */
  delimiter?: string;
  /** Flush buffer when silence detected */
  flush_on_silence?: boolean;
}

/** Splits audio into fixed-size chunks - Configuration */
export interface AudioChunkerConfig {
  /** Chunk duration in milliseconds */
  chunk_size_ms?: number;
}

/** Flips video frames horizontally or vertically - Configuration */
export interface VideoFlipConfig {
  /** Flip horizontally */
  horizontal?: boolean;
  /** Flip vertically */
  vertical?: boolean;
}

/** Performs arithmetic operations on JSON input - Configuration */
export interface CalculatorNodeConfig {
  /** Decimal precision for results */
  precision?: number;
}

/** Speech-to-text transcription using Whisper - Configuration */
export interface WhisperNodeConfig {
  /** Language code (null for auto-detect) */
  language?: string;
  /** Whisper model size */
  model?: 'tiny' | 'base' | 'small' | 'medium' | 'large' | 'large-v3';
  /** Task type */
  task?: 'transcribe' | 'translate';
}

/** Text-to-speech synthesis using Kokoro TTS - Configuration */
export interface KokoroTTSNodeConfig {
  /** Language code */
  language?: 'en-us' | 'en-gb' | 'es' | 'fr' | 'de' | 'it' | 'ja' | 'ko' | 'pt-br' | 'zh';
  /** Speech speed multiplier */
  speed?: number;
  /** Voice ID to use */
  voice?: 'af_bella' | 'af_nicole' | 'af_sarah' | 'af_sky' | 'am_adam' | 'am_michael' | 'bf_emma' | 'bf_isabella' | 'bm_george' | 'bm_lewis';
}

/** Node metadata from registry */
export interface NodeMetadata {
  nodeType: string;
  description?: string;
  category?: string;
  accepts: RuntimeDataType[];
  produces: RuntimeDataType[];
  isPython: boolean;
  streaming: boolean;
  multiOutput: boolean;
}

/** All registered node types */
export type NodeType =
  | 'AudioResample'
  | 'SileroVAD'
  | 'TextCollector'
  | 'AudioChunker'
  | 'VideoFlip'
  | 'PassThrough'
  | 'CalculatorNode'
  | 'Echo'
  | 'WhisperNode'
  | 'KokoroTTSNode';

/** Node type to config type mapping */
export interface NodeConfigMap {
  'AudioResample': AudioResampleConfig;
  'SileroVAD': SileroVADConfig;
  'TextCollector': TextCollectorConfig;
  'AudioChunker': AudioChunkerConfig;
  'VideoFlip': VideoFlipConfig;
  'PassThrough': Record<string, unknown>;
  'CalculatorNode': CalculatorNodeConfig;
  'Echo': Record<string, unknown>;
  'WhisperNode': WhisperNodeConfig;
  'KokoroTTSNode': KokoroTTSNodeConfig;
}

/** Pipeline node with typed config */
export interface PipelineNode<T extends NodeType = NodeType> {
  id: string;
  nodeType: T;
  config?: T extends keyof NodeConfigMap ? NodeConfigMap[T] : Record<string, unknown>;
}

/** Pipeline manifest */
export interface PipelineManifest {
  version: string;
  metadata?: { name?: string; description?: string; [key: string]: unknown };
  nodes: PipelineNode[];
  connections: Array<{
    source: string;
    sourcePort?: string;
    destination: string;
    destinationPort?: string;
  }>;
}

/** All node schemas (for runtime introspection) */
export const nodeSchemas: NodeMetadata[] = [
  {
    "nodeType": "AudioResample",
    "description": "Resamples audio to target sample rate",
    "category": "audio",
    "accepts": [
      "audio"
    ],
    "produces": [
      "audio"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "SileroVAD",
    "description": "Voice Activity Detection using Silero VAD model",
    "category": "audio",
    "accepts": [
      "audio"
    ],
    "produces": [
      "audio",
      "controlmessage"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "TextCollector",
    "description": "Collects text chunks into complete utterances",
    "category": "text",
    "accepts": [
      "text"
    ],
    "produces": [
      "text"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "AudioChunker",
    "description": "Splits audio into fixed-size chunks",
    "category": "audio",
    "accepts": [
      "audio"
    ],
    "produces": [
      "audio"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": true
  },
  {
    "nodeType": "VideoFlip",
    "description": "Flips video frames horizontally or vertically",
    "category": "video",
    "accepts": [
      "video"
    ],
    "produces": [
      "video"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "PassThrough",
    "description": "Passes input through unchanged",
    "category": "utility",
    "accepts": [
      "audio",
      "video",
      "json",
      "text",
      "binary",
      "tensor",
      "numpy",
      "controlmessage"
    ],
    "produces": [
      "audio",
      "video",
      "json",
      "text",
      "binary",
      "tensor",
      "numpy",
      "controlmessage"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "CalculatorNode",
    "description": "Performs arithmetic operations on JSON input",
    "category": "utility",
    "accepts": [
      "json"
    ],
    "produces": [
      "json"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "Echo",
    "description": "Passes input through unchanged (for testing)",
    "category": "utility",
    "accepts": [
      "audio",
      "video",
      "json",
      "text",
      "binary",
      "tensor",
      "numpy",
      "controlmessage"
    ],
    "produces": [
      "audio",
      "video",
      "json",
      "text",
      "binary",
      "tensor",
      "numpy",
      "controlmessage"
    ],
    "isPython": false,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "WhisperNode",
    "description": "Speech-to-text transcription using Whisper",
    "category": "ml",
    "accepts": [
      "audio"
    ],
    "produces": [
      "text",
      "json"
    ],
    "isPython": true,
    "streaming": true,
    "multiOutput": false
  },
  {
    "nodeType": "KokoroTTSNode",
    "description": "Text-to-speech synthesis using Kokoro TTS",
    "category": "ml",
    "accepts": [
      "text"
    ],
    "produces": [
      "audio"
    ],
    "isPython": true,
    "streaming": true,
    "multiOutput": true
  }
];

// =============================================================================
// Node Builder Classes
// =============================================================================

/**
 * Base class for all node builders.
 * Provides type-safe construction of pipeline nodes.
 */
export abstract class NodeBuilder<T extends NodeType = NodeType, C = unknown> {
  readonly id: string;
  readonly nodeType: T;
  readonly config?: C;

  constructor(id: string, nodeType: T, config?: C) {
    this.id = id;
    this.nodeType = nodeType;
    this.config = config;
  }

  /** Convert to PipelineNode format for manifest */
  toPipelineNode(): PipelineNode<T> {
    return {
      id: this.id,
      nodeType: this.nodeType,
      config: this.config as T extends keyof NodeConfigMap ? NodeConfigMap[T] : Record<string, unknown>,
    };
  }

  /** Create connection to another node */
  connectTo(target: NodeBuilder<NodeType, unknown> | string, sourcePort?: string, destinationPort?: string): PipelineConnection {
    const targetId = typeof target === 'string' ? target : target.id;
    return {
      source: this.id,
      sourcePort,
      destination: targetId,
      destinationPort,
    };
  }
}

/** Connection between pipeline nodes */
export interface PipelineConnection {
  source: string;
  sourcePort?: string;
  destination: string;
  destinationPort?: string;
}

/**
 * Resamples audio to target sample rate
 *
 * @example
 * ```typescript
 * const node = new AudioResample('my-audioresample', { });
 * pipeline.addNode(node);
 * ```
 */
export class AudioResample extends NodeBuilder<'AudioResample', AudioResampleConfig> {
  static readonly nodeType = 'AudioResample' as const;
  static readonly accepts: RuntimeDataType[] = ['audio'];
  static readonly produces: RuntimeDataType[] = ['audio'];

  constructor(id: string, config?: AudioResampleConfig) {
    super(id, 'AudioResample', config);
  }
}

/**
 * Voice Activity Detection using Silero VAD model
 *
 * @example
 * ```typescript
 * const node = new SileroVAD('my-silerovad', { });
 * pipeline.addNode(node);
 * ```
 */
export class SileroVAD extends NodeBuilder<'SileroVAD', SileroVADConfig> {
  static readonly nodeType = 'SileroVAD' as const;
  static readonly accepts: RuntimeDataType[] = ['audio'];
  static readonly produces: RuntimeDataType[] = ['audio', 'controlmessage'];

  constructor(id: string, config?: SileroVADConfig) {
    super(id, 'SileroVAD', config);
  }
}

/**
 * Collects text chunks into complete utterances
 *
 * @example
 * ```typescript
 * const node = new TextCollector('my-textcollector', { });
 * pipeline.addNode(node);
 * ```
 */
export class TextCollector extends NodeBuilder<'TextCollector', TextCollectorConfig> {
  static readonly nodeType = 'TextCollector' as const;
  static readonly accepts: RuntimeDataType[] = ['text'];
  static readonly produces: RuntimeDataType[] = ['text'];

  constructor(id: string, config?: TextCollectorConfig) {
    super(id, 'TextCollector', config);
  }
}

/**
 * Splits audio into fixed-size chunks
 *
 * @example
 * ```typescript
 * const node = new AudioChunker('my-audiochunker', { });
 * pipeline.addNode(node);
 * ```
 */
export class AudioChunker extends NodeBuilder<'AudioChunker', AudioChunkerConfig> {
  static readonly nodeType = 'AudioChunker' as const;
  static readonly accepts: RuntimeDataType[] = ['audio'];
  static readonly produces: RuntimeDataType[] = ['audio'];

  constructor(id: string, config?: AudioChunkerConfig) {
    super(id, 'AudioChunker', config);
  }
}

/**
 * Flips video frames horizontally or vertically
 *
 * @example
 * ```typescript
 * const node = new VideoFlip('my-videoflip', { });
 * pipeline.addNode(node);
 * ```
 */
export class VideoFlip extends NodeBuilder<'VideoFlip', VideoFlipConfig> {
  static readonly nodeType = 'VideoFlip' as const;
  static readonly accepts: RuntimeDataType[] = ['video'];
  static readonly produces: RuntimeDataType[] = ['video'];

  constructor(id: string, config?: VideoFlipConfig) {
    super(id, 'VideoFlip', config);
  }
}

/**
 * Passes input through unchanged
 *
 * @example
 * ```typescript
 * const node = new PassThrough('my-passthrough');
 * pipeline.addNode(node);
 * ```
 */
export class PassThrough extends NodeBuilder<'PassThrough', Record<string, unknown>> {
  static readonly nodeType = 'PassThrough' as const;
  static readonly accepts: RuntimeDataType[] = ['audio', 'video', 'json', 'text', 'binary', 'tensor', 'numpy', 'controlmessage'];
  static readonly produces: RuntimeDataType[] = ['audio', 'video', 'json', 'text', 'binary', 'tensor', 'numpy', 'controlmessage'];

  constructor(id: string, config?: Record<string, unknown>) {
    super(id, 'PassThrough', config);
  }
}

/**
 * Performs arithmetic operations on JSON input
 *
 * @example
 * ```typescript
 * const node = new CalculatorNode('my-calculatornode', { });
 * pipeline.addNode(node);
 * ```
 */
export class CalculatorNode extends NodeBuilder<'CalculatorNode', CalculatorNodeConfig> {
  static readonly nodeType = 'CalculatorNode' as const;
  static readonly accepts: RuntimeDataType[] = ['json'];
  static readonly produces: RuntimeDataType[] = ['json'];

  constructor(id: string, config?: CalculatorNodeConfig) {
    super(id, 'CalculatorNode', config);
  }
}

/**
 * Passes input through unchanged (for testing)
 *
 * @example
 * ```typescript
 * const node = new Echo('my-echo');
 * pipeline.addNode(node);
 * ```
 */
export class Echo extends NodeBuilder<'Echo', Record<string, unknown>> {
  static readonly nodeType = 'Echo' as const;
  static readonly accepts: RuntimeDataType[] = ['audio', 'video', 'json', 'text', 'binary', 'tensor', 'numpy', 'controlmessage'];
  static readonly produces: RuntimeDataType[] = ['audio', 'video', 'json', 'text', 'binary', 'tensor', 'numpy', 'controlmessage'];

  constructor(id: string, config?: Record<string, unknown>) {
    super(id, 'Echo', config);
  }
}

/**
 * Speech-to-text transcription using Whisper
 *
 * @example
 * ```typescript
 * const node = new WhisperNode('my-whispernode', { });
 * pipeline.addNode(node);
 * ```
 */
export class WhisperNode extends NodeBuilder<'WhisperNode', WhisperNodeConfig> {
  static readonly nodeType = 'WhisperNode' as const;
  static readonly accepts: RuntimeDataType[] = ['audio'];
  static readonly produces: RuntimeDataType[] = ['text', 'json'];

  constructor(id: string, config?: WhisperNodeConfig) {
    super(id, 'WhisperNode', config);
  }
}

/**
 * Text-to-speech synthesis using Kokoro TTS
 *
 * @example
 * ```typescript
 * const node = new KokoroTTSNode('my-kokorottsnode', { });
 * pipeline.addNode(node);
 * ```
 */
export class KokoroTTSNode extends NodeBuilder<'KokoroTTSNode', KokoroTTSNodeConfig> {
  static readonly nodeType = 'KokoroTTSNode' as const;
  static readonly accepts: RuntimeDataType[] = ['text'];
  static readonly produces: RuntimeDataType[] = ['audio'];

  constructor(id: string, config?: KokoroTTSNodeConfig) {
    super(id, 'KokoroTTSNode', config);
  }
}

/** Namespace containing all node builder classes */
export const Nodes = {
  AudioResample,
  SileroVAD,
  TextCollector,
  AudioChunker,
  VideoFlip,
  PassThrough,
  CalculatorNode,
  Echo,
  WhisperNode,
  KokoroTTSNode
} as const;

/**
 * Fluent pipeline builder for constructing manifests.
 *
 * @example
 * ```typescript
 * const manifest = new PipelineBuilder('1.0')
 *   .name('My Pipeline')
 *   .add(new SileroVAD('vad', { threshold: 0.6 }))
 *   .add(new WhisperNode('whisper', { model: 'base' }))
 *   .connect('vad', 'whisper')
 *   .build();
 * ```
 */
export class PipelineBuilder {
  private version: string;
  private metadata: { name?: string; description?: string; [key: string]: unknown } = {};
  private nodes: PipelineNode[] = [];
  private connections: PipelineConnection[] = [];

  constructor(version: string = '1.0') {
    this.version = version;
  }

  /** Set pipeline name */
  name(name: string): this {
    this.metadata.name = name;
    return this;
  }

  /** Set pipeline description */
  description(description: string): this {
    this.metadata.description = description;
    return this;
  }

  /** Add metadata key-value */
  meta(key: string, value: unknown): this {
    this.metadata[key] = value;
    return this;
  }

  /** Add a node to the pipeline */
  add(node: NodeBuilder<NodeType, unknown>): this {
    this.nodes.push(node.toPipelineNode());
    return this;
  }

  /** Add a raw node definition */
  addRaw<T extends NodeType>(node: PipelineNode<T>): this {
    this.nodes.push(node);
    return this;
  }

  /** Connect two nodes */
  connect(
    source: NodeBuilder<NodeType, unknown> | string,
    destination: NodeBuilder<NodeType, unknown> | string,
    sourcePort?: string,
    destinationPort?: string
  ): this {
    const sourceId = typeof source === 'string' ? source : source.id;
    const destId = typeof destination === 'string' ? destination : destination.id;
    this.connections.push({
      source: sourceId,
      sourcePort,
      destination: destId,
      destinationPort,
    });
    return this;
  }

  /** Build the final pipeline manifest */
  build(): PipelineManifest {
    return {
      version: this.version,
      metadata: Object.keys(this.metadata).length > 0 ? this.metadata : undefined,
      nodes: this.nodes,
      connections: this.connections,
    };
  }

  /** Convert to JSON string */
  toJson(): string {
    return JSON.stringify(this.build(), null, 2);
  }
}
