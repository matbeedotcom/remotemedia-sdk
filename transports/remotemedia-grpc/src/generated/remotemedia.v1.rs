// This file is @generated by prost-build.
/// Universal container for any protocol bufferable data type
///
/// Uses protobuf oneof discriminator for type-safe variant selection.
/// Exactly one variant must be set.
///
/// Usage:
/// DataBuffer audio_buf = {
/// audio: { samples: ..., sample_rate: 16000, ... }
/// };
///
/// DataBuffer json_buf = {
/// json: { json_payload: "{"operation": "add"}", ... }
/// };
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DataBuffer {
    /// Optional metadata for extensibility
    /// Examples: compression="gzip", encoding="base64", custom_key="value"
    /// Convention: Use lowercase snake_case for keys
    #[prost(map = "string, string", tag = "10")]
    pub metadata: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Data type discriminator (exactly one must be set)
    #[prost(oneof = "data_buffer::DataType", tags = "1, 2, 3, 4, 5, 6, 7")]
    pub data_type: ::core::option::Option<data_buffer::DataType>,
}
/// Nested message and enum types in `DataBuffer`.
pub mod data_buffer {
    /// Data type discriminator (exactly one must be set)
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum DataType {
        #[prost(message, tag = "1")]
        Audio(super::AudioBuffer),
        #[prost(message, tag = "2")]
        Video(super::VideoFrame),
        #[prost(message, tag = "3")]
        Tensor(super::TensorBuffer),
        #[prost(message, tag = "4")]
        Json(super::JsonData),
        #[prost(message, tag = "5")]
        Text(super::TextBuffer),
        #[prost(message, tag = "6")]
        Binary(super::BinaryBuffer),
        /// Spec 007: Control messages for low-latency streaming
        #[prost(message, tag = "7")]
        Control(super::ControlMessage),
    }
}
/// Multi-channel audio data with sample rate and format metadata
///
/// Samples are stored in interleaved format for multi-channel audio.
/// For stereo: \[L0, R0, L1, R1, L2, R2, ...\]
///
/// This type is unchanged from Feature 003 to maintain backward compatibility.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct AudioBuffer {
    /// Raw audio samples (interleaved, little-endian)
    /// Size = num_samples * channels * format.bytes_per_sample()
    #[prost(bytes = "vec", tag = "1")]
    pub samples: ::prost::alloc::vec::Vec<u8>,
    /// Sample rate in Hz (e.g., 8000, 16000, 44100, 48000)
    #[prost(uint32, tag = "2")]
    pub sample_rate: u32,
    /// Number of channels (1=mono, 2=stereo, 6=5.1 surround)
    #[prost(uint32, tag = "3")]
    pub channels: u32,
    /// Audio sample encoding format
    #[prost(enumeration = "AudioFormat", tag = "4")]
    pub format: i32,
    /// Total number of samples (including all channels)
    /// num_frames = num_samples / channels
    /// duration_seconds = num_frames / sample_rate
    #[prost(uint64, tag = "5")]
    pub num_samples: u64,
}
/// Video frame data with pixel format and dimensions
///
/// Supports common uncompressed pixel formats.
/// Codec support (H.264, H.265) is out of scope - nodes handle encoding if needed.
///
/// Validation:
/// pixel_data.len() == width * height * format.bytes_per_pixel()
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VideoFrame {
    /// Raw pixel data (format specified by format field)
    /// Layout determined by PixelFormat
    #[prost(bytes = "vec", tag = "1")]
    pub pixel_data: ::prost::alloc::vec::Vec<u8>,
    /// Frame width in pixels (must be > 0)
    #[prost(uint32, tag = "2")]
    pub width: u32,
    /// Frame height in pixels (must be > 0)
    #[prost(uint32, tag = "3")]
    pub height: u32,
    /// Pixel format
    #[prost(enumeration = "PixelFormat", tag = "4")]
    pub format: i32,
    /// Frame sequence number for ordering
    #[prost(uint64, tag = "5")]
    pub frame_number: u64,
    /// Timestamp in microseconds (for synchronization)
    #[prost(uint64, tag = "6")]
    pub timestamp_us: u64,
}
/// Multi-dimensional tensor data with shape and dtype
///
/// Supports ML use cases: embeddings, image tensors, model inputs/outputs.
/// Data stored in row-major layout by default.
///
/// Validation:
/// data.len() == shape.product() * dtype.bytes_per_element()
///
/// Example (512-dim embedding, F32):
/// TensorBuffer {
/// data: \<2048 bytes>,
/// shape: \[512\],
/// dtype: TENSOR_DTYPE_F32
/// }
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct TensorBuffer {
    /// Raw tensor data (row-major layout by default)
    /// Must match calculated size from shape and dtype
    #[prost(bytes = "vec", tag = "1")]
    pub data: ::prost::alloc::vec::Vec<u8>,
    /// Shape array (e.g., \[1, 3, 224, 224\] for batch=1, channels=3, 224x224 image)
    /// Empty shape = scalar, \[N\] = vector, \[N, M\] = matrix
    #[prost(uint64, repeated, tag = "2")]
    pub shape: ::prost::alloc::vec::Vec<u64>,
    /// Data type
    #[prost(enumeration = "TensorDtype", tag = "3")]
    pub dtype: i32,
    /// Optional layout hint ("NCHW", "NHWC", "row-major", etc.)
    /// Nodes document expected layout in capabilities
    /// No automatic conversion performed
    #[prost(string, tag = "4")]
    pub layout: ::prost::alloc::string::String,
}
/// JSON payload for structured data, control parameters, and metadata
///
/// Server always parses JSON into serde_json::Value for validation.
/// Nodes work with structured data (easier than string manipulation).
///
/// Example (Calculator request):
/// JsonData {
/// json_payload: "{"operation": "add", "operands": \[10, 20\]}",
/// schema_type: "CalculatorRequest"
/// }
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct JsonData {
    /// JSON payload as string (required, must be valid JSON)
    #[prost(string, tag = "1")]
    pub json_payload: ::prost::alloc::string::String,
    /// Optional schema type hint for validation
    /// Example: "CalculatorRequest", "VADConfig", "DetectionResult"
    /// Nodes can use this to validate structure
    #[prost(string, tag = "2")]
    pub schema_type: ::prost::alloc::string::String,
}
/// UTF-8 text data with optional encoding and language metadata
///
/// Validation: Server validates UTF-8 correctness
///
/// Example:
/// TextBuffer {
/// text_data: "Hello, world!",  // UTF-8 bytes
/// encoding: "utf-8",
/// language: "en"
/// }
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct TextBuffer {
    /// Text data as UTF-8 encoded bytes
    /// Server validates UTF-8 correctness
    #[prost(bytes = "vec", tag = "1")]
    pub text_data: ::prost::alloc::vec::Vec<u8>,
    /// Text encoding (default: "utf-8")
    /// Other values: "ascii", "utf-16"
    #[prost(string, tag = "2")]
    pub encoding: ::prost::alloc::string::String,
    /// Optional language code (ISO 639-1, e.g., "en", "es", "zh")
    /// Used for NLP, tokenization, etc.
    #[prost(string, tag = "3")]
    pub language: ::prost::alloc::string::String,
}
/// Raw binary data with mime type hint
///
/// No validation beyond size limits.
/// MIME type accuracy is client responsibility (not validated by protocol).
///
/// Example (PNG image):
/// BinaryBuffer {
/// data: <PNG file bytes>,
/// mime_type: "image/png"
/// }
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct BinaryBuffer {
    /// Raw binary data
    #[prost(bytes = "vec", tag = "1")]
    pub data: ::prost::alloc::vec::Vec<u8>,
    /// MIME type hint
    /// Examples: "application/octet-stream", "image/png", "application/protobuf"
    /// Not validated by protocol (client responsibility)
    #[prost(string, tag = "2")]
    pub mime_type: ::prost::alloc::string::String,
}
/// Control message for pipeline flow control
///
/// Enables low-latency optimizations:
///
/// * CancelSpeculation: Cancel processing of speculative audio segments
/// * BatchHint: Suggest batching parameters to downstream nodes
/// * DeadlineWarning: Signal approaching soft deadlines
///
/// Example (Cancel speculation):
/// ControlMessage {
/// message_type: { cancel_speculation: { from_timestamp: 1000, to_timestamp: 2000 } },
/// segment_id: "seg_abc123",
/// timestamp_ms: 1500
/// }
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ControlMessage {
    /// Optional target segment ID for cancellation
    #[prost(string, tag = "4")]
    pub segment_id: ::prost::alloc::string::String,
    /// Message creation timestamp (milliseconds since epoch)
    #[prost(uint64, tag = "5")]
    pub timestamp_ms: u64,
    /// Extensible metadata (JSON encoded)
    /// Example: {"reason": "vad_false_positive", "confidence": 0.3}
    #[prost(string, tag = "6")]
    pub metadata: ::prost::alloc::string::String,
    /// Control message type (exactly one must be set)
    #[prost(oneof = "control_message::MessageType", tags = "1, 2, 3")]
    pub message_type: ::core::option::Option<control_message::MessageType>,
}
/// Nested message and enum types in `ControlMessage`.
pub mod control_message {
    /// Control message type (exactly one must be set)
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum MessageType {
        #[prost(message, tag = "1")]
        CancelSpeculation(super::CancelSpeculation),
        #[prost(message, tag = "2")]
        BatchHint(super::BatchHint),
        #[prost(message, tag = "3")]
        DeadlineWarning(super::DeadlineWarning),
    }
}
/// Cancel a speculative segment (retroactive cancellation)
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CancelSpeculation {
    /// Start timestamp of segment to cancel (sample index or microseconds)
    #[prost(uint64, tag = "1")]
    pub from_timestamp: u64,
    /// End timestamp of segment to cancel
    #[prost(uint64, tag = "2")]
    pub to_timestamp: u64,
}
/// Hint to increase batch size for throughput
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct BatchHint {
    /// Suggested batch size for downstream nodes
    #[prost(uint32, tag = "1")]
    pub suggested_batch_size: u32,
}
/// Soft deadline approaching (not a hard timeout)
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DeadlineWarning {
    /// Deadline in microseconds from now
    #[prost(uint64, tag = "1")]
    pub deadline_us: u64,
}
/// Performance metrics for pipeline execution
///
/// UPDATED: Added serialization_time_ms and data_type_breakdown
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutionMetrics {
    /// Wall-clock time from request receipt to response ready (milliseconds)
    /// Target: \<5ms for simple operations (SC-001)
    #[prost(double, tag = "1")]
    pub wall_time_ms: f64,
    /// Total CPU time consumed by all threads (milliseconds)
    #[prost(double, tag = "2")]
    pub cpu_time_ms: f64,
    /// Peak memory usage during execution (bytes)
    /// Target: \<10MB per concurrent execution (SC-008)
    #[prost(uint64, tag = "3")]
    pub memory_used_bytes: u64,
    /// Per-node execution statistics (keyed by node ID)
    #[prost(map = "string, message", tag = "4")]
    pub node_metrics: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        NodeMetrics,
    >,
    /// Time spent serializing/deserializing protobuf messages (milliseconds)
    /// Target: \<10% of wall_time_ms (SC-003)
    #[prost(double, tag = "5")]
    pub serialization_time_ms: f64,
    /// NEW: Proto ↔ Runtime conversion overhead
    /// Measures DataBuffer → RuntimeData → DataBuffer conversion time
    #[prost(double, tag = "6")]
    pub proto_to_runtime_ms: f64,
    #[prost(double, tag = "7")]
    pub runtime_to_proto_ms: f64,
    /// NEW: Track data type distribution
    /// Keys: "audio", "video", "tensor", "json", "text", "binary"
    /// Values: Count of chunks/buffers processed per type
    #[prost(map = "string, uint64", tag = "8")]
    pub data_type_breakdown: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        u64,
    >,
}
/// Performance metrics for a single node execution
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NodeMetrics {
    /// Time spent executing this node's process() method (milliseconds)
    #[prost(double, tag = "1")]
    pub execution_time_ms: f64,
    /// Memory allocated by this node (bytes)
    #[prost(uint64, tag = "2")]
    pub memory_bytes: u64,
    /// UPDATED: Generic item count (was samples_processed)
    /// Audio: samples, Video: frames, Tensor: elements, JSON: objects, Text: characters
    #[prost(uint64, tag = "3")]
    pub items_processed: u64,
    /// Node-specific metrics (JSON encoded)
    /// Example: {"vad_segments": 12, "silence_ratio": 0.45}
    #[prost(string, tag = "4")]
    pub custom_metrics: ::prost::alloc::string::String,
}
/// Structured error information for debugging and diagnostics
///
/// UPDATED: Added ERROR_TYPE_TYPE_VALIDATION for generic type errors
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ErrorResponse {
    /// Error category for programmatic handling
    #[prost(enumeration = "ErrorType", tag = "1")]
    pub error_type: i32,
    /// Human-readable error message
    #[prost(string, tag = "2")]
    pub message: ::prost::alloc::string::String,
    /// Node ID where error occurred (empty for manifest validation errors)
    #[prost(string, tag = "3")]
    pub failing_node_id: ::prost::alloc::string::String,
    /// Execution context at time of error (JSON encoded)
    /// Example: {"expected_type": "AUDIO", "actual_type": "VIDEO"}
    #[prost(string, tag = "4")]
    pub context: ::prost::alloc::string::String,
    /// Rust panic stack trace (if available)
    #[prost(string, tag = "5")]
    pub stack_trace: ::prost::alloc::string::String,
}
/// Service version and protocol compatibility information
///
/// Returned by GetVersion() RPC to enable client compatibility checks.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VersionInfo {
    /// Current protocol version (e.g., "v1")
    #[prost(string, tag = "1")]
    pub protocol_version: ::prost::alloc::string::String,
    /// Rust runtime version (e.g., "0.2.1")
    #[prost(string, tag = "2")]
    pub runtime_version: ::prost::alloc::string::String,
    /// List of supported node types registered in this service
    /// Example: \["AudioResample", "VAD", "HFPipelineNode"\]
    #[prost(string, repeated, tag = "3")]
    pub supported_node_types: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// All protocol versions this service supports
    /// Example: \["v1"\] initially, may expand to \["v1", "v2"\]
    #[prost(string, repeated, tag = "4")]
    pub supported_protocols: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Service build timestamp (ISO 8601)
    /// Example: "2025-10-28T10:30:00Z"
    #[prost(string, tag = "5")]
    pub build_timestamp: ::prost::alloc::string::String,
}
/// Configurable resource constraints for pipeline execution
///
/// Clients can request custom limits within service-defined maximums.
/// Service applies defaults if not specified.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ResourceLimits {
    /// Maximum memory allocation (bytes)
    /// Default: 100MB, Max: 1GB (configurable per service)
    #[prost(uint64, tag = "1")]
    pub max_memory_bytes: u64,
    /// Maximum execution timeout (milliseconds)
    /// Default: 5000ms, Max: 30000ms (configurable per service)
    #[prost(uint64, tag = "2")]
    pub max_timeout_ms: u64,
    /// Maximum audio buffer size (samples, across all channels)
    /// Default: 10M samples (~200MB stereo F32)
    /// Prevents out-of-memory attacks
    #[prost(uint64, tag = "3")]
    pub max_audio_samples: u64,
}
/// Execution details for a single node
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct NodeResult {
    /// Node ID from manifest
    #[prost(string, tag = "1")]
    pub node_id: ::prost::alloc::string::String,
    /// Execution status
    #[prost(enumeration = "NodeStatus", tag = "2")]
    pub status: i32,
    /// Error details (only if status == NODE_STATUS_FAILED)
    #[prost(message, optional, tag = "3")]
    pub error: ::core::option::Option<ErrorResponse>,
    /// Node-specific output metadata (JSON encoded)
    /// Example: {"output_format": "f32", "channels": 2}
    #[prost(string, tag = "4")]
    pub output_metadata: ::prost::alloc::string::String,
}
/// Audio sample encoding format
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum AudioFormat {
    Unspecified = 0,
    /// 32-bit floating point, range \[-1.0, 1.0\]
    /// 4 bytes per sample
    F32 = 1,
    /// 16-bit signed integer, range \[-32768, 32767\]
    /// 2 bytes per sample (most common format)
    I16 = 2,
    /// 32-bit signed integer
    /// 4 bytes per sample
    I32 = 3,
}
impl AudioFormat {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "AUDIO_FORMAT_UNSPECIFIED",
            Self::F32 => "AUDIO_FORMAT_F32",
            Self::I16 => "AUDIO_FORMAT_I16",
            Self::I32 => "AUDIO_FORMAT_I32",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "AUDIO_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
            "AUDIO_FORMAT_F32" => Some(Self::F32),
            "AUDIO_FORMAT_I16" => Some(Self::I16),
            "AUDIO_FORMAT_I32" => Some(Self::I32),
            _ => None,
        }
    }
}
/// Pixel format enumeration
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum PixelFormat {
    Unspecified = 0,
    /// Packed RGB, 8-bit per channel (3 bytes/pixel)
    /// Layout: \[R, G, B, R, G, B, ...\]
    Rgb24 = 1,
    /// Packed RGBA, 8-bit per channel (4 bytes/pixel)
    /// Layout: \[R, G, B, A, R, G, B, A, ...\]
    Rgba32 = 2,
    /// Planar YUV 4:2:0 (1.5 bytes/pixel)
    /// Y plane: width*height, U plane: (width/2)*(height/2), V plane: same as U
    Yuv420p = 3,
    /// Grayscale, 8-bit (1 byte/pixel)
    Gray8 = 4,
}
impl PixelFormat {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "PIXEL_FORMAT_UNSPECIFIED",
            Self::Rgb24 => "PIXEL_FORMAT_RGB24",
            Self::Rgba32 => "PIXEL_FORMAT_RGBA32",
            Self::Yuv420p => "PIXEL_FORMAT_YUV420P",
            Self::Gray8 => "PIXEL_FORMAT_GRAY8",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "PIXEL_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
            "PIXEL_FORMAT_RGB24" => Some(Self::Rgb24),
            "PIXEL_FORMAT_RGBA32" => Some(Self::Rgba32),
            "PIXEL_FORMAT_YUV420P" => Some(Self::Yuv420p),
            "PIXEL_FORMAT_GRAY8" => Some(Self::Gray8),
            _ => None,
        }
    }
}
/// Tensor data type enumeration
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum TensorDtype {
    Unspecified = 0,
    /// 32-bit float (4 bytes per element)
    F32 = 1,
    /// 16-bit float (2 bytes per element)
    F16 = 2,
    /// 32-bit int (4 bytes per element)
    I32 = 3,
    /// 8-bit int (1 byte per element, quantized models)
    I8 = 4,
    /// 8-bit unsigned int (1 byte per element)
    U8 = 5,
}
impl TensorDtype {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TENSOR_DTYPE_UNSPECIFIED",
            Self::F32 => "TENSOR_DTYPE_F32",
            Self::F16 => "TENSOR_DTYPE_F16",
            Self::I32 => "TENSOR_DTYPE_I32",
            Self::I8 => "TENSOR_DTYPE_I8",
            Self::U8 => "TENSOR_DTYPE_U8",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TENSOR_DTYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "TENSOR_DTYPE_F32" => Some(Self::F32),
            "TENSOR_DTYPE_F16" => Some(Self::F16),
            "TENSOR_DTYPE_I32" => Some(Self::I32),
            "TENSOR_DTYPE_I8" => Some(Self::I8),
            "TENSOR_DTYPE_U8" => Some(Self::U8),
            _ => None,
        }
    }
}
/// Data type hint for compile-time and runtime type validation
///
/// Used in NodeManifest to declare expected input/output types.
/// Enables three-layer validation:
///
/// 1. Compile-time: TypeScript/Python type checking
/// 1. Manifest validation: Connection type compatibility at StreamInit
/// 1. Runtime: Chunk type validation per chunk
///
/// Example (VAD node: audio in, JSON out):
/// NodeManifest {
/// id: "vad",
/// node_type: "RustVADNode",
/// input_types: \[DATA_TYPE_HINT_AUDIO\],
/// output_types: \[DATA_TYPE_HINT_JSON\]
/// }
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum DataTypeHint {
    Unspecified = 0,
    Audio = 1,
    Video = 2,
    Tensor = 3,
    Json = 4,
    Text = 5,
    Binary = 6,
    /// Accept any type (polymorphic node)
    /// Example: generic logger, passthrough, inspector
    Any = 7,
}
impl DataTypeHint {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "DATA_TYPE_HINT_UNSPECIFIED",
            Self::Audio => "DATA_TYPE_HINT_AUDIO",
            Self::Video => "DATA_TYPE_HINT_VIDEO",
            Self::Tensor => "DATA_TYPE_HINT_TENSOR",
            Self::Json => "DATA_TYPE_HINT_JSON",
            Self::Text => "DATA_TYPE_HINT_TEXT",
            Self::Binary => "DATA_TYPE_HINT_BINARY",
            Self::Any => "DATA_TYPE_HINT_ANY",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "DATA_TYPE_HINT_UNSPECIFIED" => Some(Self::Unspecified),
            "DATA_TYPE_HINT_AUDIO" => Some(Self::Audio),
            "DATA_TYPE_HINT_VIDEO" => Some(Self::Video),
            "DATA_TYPE_HINT_TENSOR" => Some(Self::Tensor),
            "DATA_TYPE_HINT_JSON" => Some(Self::Json),
            "DATA_TYPE_HINT_TEXT" => Some(Self::Text),
            "DATA_TYPE_HINT_BINARY" => Some(Self::Binary),
            "DATA_TYPE_HINT_ANY" => Some(Self::Any),
            _ => None,
        }
    }
}
/// Error category enumeration
///
/// UPDATED: Added ERROR_TYPE_TYPE_VALIDATION
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ErrorType {
    Unspecified = 0,
    /// Manifest validation error (malformed JSON, invalid node IDs, cycles)
    /// Action: Fix manifest and retry
    Validation = 1,
    /// Node execution failure (invalid parameters, processing error)
    /// Action: Check node parameters and input data
    NodeExecution = 2,
    /// Resource limit exceeded (memory, timeout, buffer size)
    /// Action: Reduce pipeline complexity or request higher limits
    ResourceLimit = 3,
    /// Authentication failed (invalid/missing API token)
    /// Action: Check API token configuration
    Authentication = 4,
    /// Protocol version mismatch (incompatible client/server versions)
    /// Action: Upgrade client library
    VersionMismatch = 5,
    /// Service internal error (panic, unexpected state)
    /// Action: Retry with exponential backoff, contact support if persistent
    Internal = 6,
    /// NEW: Type validation error (type mismatch in manifest or runtime)
    /// Action: Fix type declarations or data types
    /// Example: Audio node receives video data
    TypeValidation = 7,
}
impl ErrorType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "ERROR_TYPE_UNSPECIFIED",
            Self::Validation => "ERROR_TYPE_VALIDATION",
            Self::NodeExecution => "ERROR_TYPE_NODE_EXECUTION",
            Self::ResourceLimit => "ERROR_TYPE_RESOURCE_LIMIT",
            Self::Authentication => "ERROR_TYPE_AUTHENTICATION",
            Self::VersionMismatch => "ERROR_TYPE_VERSION_MISMATCH",
            Self::Internal => "ERROR_TYPE_INTERNAL",
            Self::TypeValidation => "ERROR_TYPE_TYPE_VALIDATION",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "ERROR_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "ERROR_TYPE_VALIDATION" => Some(Self::Validation),
            "ERROR_TYPE_NODE_EXECUTION" => Some(Self::NodeExecution),
            "ERROR_TYPE_RESOURCE_LIMIT" => Some(Self::ResourceLimit),
            "ERROR_TYPE_AUTHENTICATION" => Some(Self::Authentication),
            "ERROR_TYPE_VERSION_MISMATCH" => Some(Self::VersionMismatch),
            "ERROR_TYPE_INTERNAL" => Some(Self::Internal),
            "ERROR_TYPE_TYPE_VALIDATION" => Some(Self::TypeValidation),
            _ => None,
        }
    }
}
/// Overall pipeline execution status
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ExecutionStatus {
    Unspecified = 0,
    /// All nodes executed successfully
    Success = 1,
    /// Some nodes were skipped but pipeline completed
    /// (e.g., conditional nodes based on input data)
    PartialSuccess = 2,
    /// Pipeline execution failed (see ErrorResponse for details)
    Failed = 3,
}
impl ExecutionStatus {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "EXECUTION_STATUS_UNSPECIFIED",
            Self::Success => "EXECUTION_STATUS_SUCCESS",
            Self::PartialSuccess => "EXECUTION_STATUS_PARTIAL_SUCCESS",
            Self::Failed => "EXECUTION_STATUS_FAILED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "EXECUTION_STATUS_UNSPECIFIED" => Some(Self::Unspecified),
            "EXECUTION_STATUS_SUCCESS" => Some(Self::Success),
            "EXECUTION_STATUS_PARTIAL_SUCCESS" => Some(Self::PartialSuccess),
            "EXECUTION_STATUS_FAILED" => Some(Self::Failed),
            _ => None,
        }
    }
}
/// Execution status for a single node
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum NodeStatus {
    Unspecified = 0,
    /// Node executed successfully
    Success = 1,
    /// Node was skipped (conditional execution)
    Skipped = 2,
    /// Node execution failed (see ErrorResponse for details)
    Failed = 3,
}
impl NodeStatus {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "NODE_STATUS_UNSPECIFIED",
            Self::Success => "NODE_STATUS_SUCCESS",
            Self::Skipped => "NODE_STATUS_SKIPPED",
            Self::Failed => "NODE_STATUS_FAILED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "NODE_STATUS_UNSPECIFIED" => Some(Self::Unspecified),
            "NODE_STATUS_SUCCESS" => Some(Self::Success),
            "NODE_STATUS_SKIPPED" => Some(Self::Skipped),
            "NODE_STATUS_FAILED" => Some(Self::Failed),
            _ => None,
        }
    }
}
/// Request to execute a pipeline
///
/// UPDATED: Uses generic data_inputs map
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteRequest {
    /// Pipeline manifest
    #[prost(message, optional, tag = "1")]
    pub manifest: ::core::option::Option<PipelineManifest>,
    /// UPDATED: Generic data inputs (keyed by node ID)
    /// Replaces separate audio_inputs and string data_inputs from Feature 003
    ///
    /// Example (audio processing):
    /// data_inputs: {
    /// "resample": DataBuffer { audio: { ... } }
    /// }
    ///
    /// Example (mixed types):
    /// data_inputs: {
    /// "vad": DataBuffer { audio: { ... } },
    /// "config": DataBuffer { json: { threshold: 0.5 } }
    /// }
    ///
    /// Node IDs must match nodes in manifest that require input
    #[prost(map = "string, message", tag = "2")]
    pub data_inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        DataBuffer,
    >,
    /// Optional resource limits for this execution
    /// If not specified, service applies default limits
    #[prost(message, optional, tag = "3")]
    pub resource_limits: ::core::option::Option<ResourceLimits>,
    /// Client protocol version (e.g., "v1")
    /// Service validates compatibility and returns ERROR_TYPE_VERSION_MISMATCH if incompatible
    #[prost(string, tag = "4")]
    pub client_version: ::prost::alloc::string::String,
}
/// Response from pipeline execution (unchanged from Feature 003)
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteResponse {
    /// Either result or error (mutually exclusive)
    #[prost(oneof = "execute_response::Outcome", tags = "1, 2")]
    pub outcome: ::core::option::Option<execute_response::Outcome>,
}
/// Nested message and enum types in `ExecuteResponse`.
pub mod execute_response {
    /// Either result or error (mutually exclusive)
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Outcome {
        /// Execution result (if successful)
        #[prost(message, tag = "1")]
        Result(super::ExecutionResult),
        /// Error details (if execution failed)
        #[prost(message, tag = "2")]
        Error(super::ErrorResponse),
    }
}
/// Pipeline manifest structure (v1)
///
/// UPDATED: NodeManifest adds input_types and output_types for type validation
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PipelineManifest {
    /// Schema version (e.g., "v1")
    /// Service validates this matches supported versions
    #[prost(string, tag = "1")]
    pub version: ::prost::alloc::string::String,
    /// Pipeline metadata
    #[prost(message, optional, tag = "2")]
    pub metadata: ::core::option::Option<ManifestMetadata>,
    /// List of processing nodes
    /// Must contain at least one node
    /// Node IDs must be unique
    #[prost(message, repeated, tag = "3")]
    pub nodes: ::prost::alloc::vec::Vec<NodeManifest>,
    /// Connections between nodes (directed edges)
    /// Forms a directed acyclic graph (DAG)
    #[prost(message, repeated, tag = "4")]
    pub connections: ::prost::alloc::vec::Vec<Connection>,
}
/// Pipeline metadata (unchanged from Feature 003)
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ManifestMetadata {
    /// Pipeline name (required)
    /// Used in logs and metrics
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional human-readable description
    #[prost(string, tag = "2")]
    pub description: ::prost::alloc::string::String,
    /// ISO 8601 timestamp of creation
    /// Example: "2025-10-28T10:30:00Z"
    #[prost(string, tag = "3")]
    pub created_at: ::prost::alloc::string::String,
}
/// Node manifest entry
///
/// UPDATED: Added input_types and output_types for type validation
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NodeManifest {
    /// Unique node ID within pipeline
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Node type (class name)
    /// Example: "AudioResample", "VAD", "HFPipelineNode"
    /// Service validates against registered node types
    #[prost(string, tag = "2")]
    pub node_type: ::prost::alloc::string::String,
    /// Node-specific parameters (JSON encoded)
    /// Service deserializes into serde_json::Value
    /// Example: "{"target_sample_rate": 16000}"
    #[prost(string, tag = "3")]
    pub params: ::prost::alloc::string::String,
    /// Whether node uses streaming (async generator)
    /// If true, node's process() method is an async generator
    #[prost(bool, tag = "4")]
    pub is_streaming: bool,
    /// Optional capability requirements (GPU, CPU, memory)
    #[prost(message, optional, tag = "5")]
    pub capabilities: ::core::option::Option<CapabilityRequirements>,
    /// Optional execution host preference (reserved for future)
    #[prost(string, tag = "6")]
    pub host: ::prost::alloc::string::String,
    /// Optional runtime hint for Python nodes
    #[prost(enumeration = "RuntimeHint", tag = "7")]
    pub runtime_hint: i32,
    /// NEW: Declare expected input types
    /// Used for three-layer validation:
    ///
    /// 1. Compile-time: Client type checking
    /// 1. Manifest validation: Connection type compatibility at StreamInit/ExecuteRequest
    /// 1. Runtime: Chunk type validation
    ///
    /// Empty list = accept any type (untyped node, backward compatible)
    /// Contains DATA_TYPE_HINT_ANY = accept any type (polymorphic node)
    ///
    /// Example (VAD node: audio only):
    /// input_types: \[DATA_TYPE_HINT_AUDIO\]
    ///
    /// Example (Multi-input filter: audio + JSON):
    /// input_types: \[DATA_TYPE_HINT_AUDIO, DATA_TYPE_HINT_JSON\]
    ///
    /// Example (Polymorphic logger: any type):
    /// input_types: \[DATA_TYPE_HINT_ANY\]
    #[prost(enumeration = "DataTypeHint", repeated, tag = "8")]
    pub input_types: ::prost::alloc::vec::Vec<i32>,
    /// NEW: Declare expected output types
    /// Used for manifest validation (connection type compatibility)
    ///
    /// Empty list = produces any type (untyped node, backward compatible)
    ///
    /// Example (VAD node: JSON output):
    /// output_types: \[DATA_TYPE_HINT_JSON\]
    ///
    /// Example (Audio filter: audio output):
    /// output_types: \[DATA_TYPE_HINT_AUDIO\]
    #[prost(enumeration = "DataTypeHint", repeated, tag = "9")]
    pub output_types: ::prost::alloc::vec::Vec<i32>,
}
/// Connection between nodes (unchanged from Feature 003)
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Connection {
    /// Source node ID (produces output)
    #[prost(string, tag = "1")]
    pub from: ::prost::alloc::string::String,
    /// Target node ID (consumes input)
    #[prost(string, tag = "2")]
    pub to: ::prost::alloc::string::String,
}
/// Hardware/resource requirements for node execution
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CapabilityRequirements {
    /// GPU requirements
    #[prost(message, optional, tag = "1")]
    pub gpu: ::core::option::Option<GpuRequirement>,
    /// CPU requirements
    #[prost(message, optional, tag = "2")]
    pub cpu: ::core::option::Option<CpuRequirement>,
    /// Memory requirement (gigabytes)
    #[prost(double, tag = "3")]
    pub memory_gb: f64,
}
/// GPU hardware requirements
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GpuRequirement {
    /// GPU type: "cuda", "rocm", "metal"
    #[prost(string, tag = "1")]
    pub r#type: ::prost::alloc::string::String,
    /// Minimum GPU memory (GB)
    #[prost(double, tag = "2")]
    pub min_memory_gb: f64,
    /// Whether GPU is required or optional
    #[prost(bool, tag = "3")]
    pub required: bool,
}
/// CPU requirements
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CpuRequirement {
    /// Minimum number of cores
    #[prost(uint32, tag = "1")]
    pub cores: u32,
    /// CPU architecture preference
    /// Example: "x86_64", "aarch64"
    #[prost(string, tag = "2")]
    pub arch: ::prost::alloc::string::String,
}
/// Result of successful pipeline execution
///
/// UPDATED: Uses generic data_outputs map
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutionResult {
    /// UPDATED: Generic data outputs (keyed by node ID)
    /// Replaces separate audio_outputs and string data_outputs from Feature 003
    /// All output types now use DataBuffer
    ///
    /// Example (audio processing):
    /// data_outputs: {
    /// "resample": DataBuffer { audio: { ... } }
    /// }
    ///
    /// Example (VAD with audio and JSON outputs):
    /// data_outputs: {
    /// "vad_audio": DataBuffer { audio: { ... } },
    /// "vad_result": DataBuffer { json: { has_speech: true } }
    /// }
    ///
    /// Empty map for pipelines with no outputs
    #[prost(map = "string, message", tag = "1")]
    pub data_outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        DataBuffer,
    >,
    /// Execution performance metrics
    #[prost(message, optional, tag = "2")]
    pub metrics: ::core::option::Option<ExecutionMetrics>,
    /// Per-node execution results
    #[prost(message, repeated, tag = "3")]
    pub node_results: ::prost::alloc::vec::Vec<NodeResult>,
    /// Overall execution status
    #[prost(enumeration = "ExecutionStatus", tag = "4")]
    pub status: i32,
}
/// Request for version information
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VersionRequest {
    /// Client version for compatibility check (e.g., "v1", "v1.2.0")
    #[prost(string, tag = "1")]
    pub client_version: ::prost::alloc::string::String,
}
/// Response with version and compatibility information
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VersionResponse {
    /// Service version details
    #[prost(message, optional, tag = "1")]
    pub version_info: ::core::option::Option<VersionInfo>,
    /// Whether client version is compatible
    #[prost(bool, tag = "2")]
    pub compatible: bool,
    /// Compatibility message (details if incompatible)
    /// Example: "Client v2 requires service v0.3.0+"
    #[prost(string, tag = "3")]
    pub compatibility_message: ::prost::alloc::string::String,
}
/// Runtime hint for Python node execution
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum RuntimeHint {
    Unspecified = 0,
    /// Use RustPython embedded interpreter (pure Rust, limited stdlib)
    Rustpython = 1,
    /// Use CPython via PyO3 in-process (full Python ecosystem, C-extensions)
    Cpython = 2,
    /// Use CPython compiled to WASM (sandboxed, Phase 3)
    CpythonWasm = 3,
    /// Automatically select runtime based on node requirements
    Auto = 4,
}
impl RuntimeHint {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "RUNTIME_HINT_UNSPECIFIED",
            Self::Rustpython => "RUNTIME_HINT_RUSTPYTHON",
            Self::Cpython => "RUNTIME_HINT_CPYTHON",
            Self::CpythonWasm => "RUNTIME_HINT_CPYTHON_WASM",
            Self::Auto => "RUNTIME_HINT_AUTO",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "RUNTIME_HINT_UNSPECIFIED" => Some(Self::Unspecified),
            "RUNTIME_HINT_RUSTPYTHON" => Some(Self::Rustpython),
            "RUNTIME_HINT_CPYTHON" => Some(Self::Cpython),
            "RUNTIME_HINT_CPYTHON_WASM" => Some(Self::CpythonWasm),
            "RUNTIME_HINT_AUTO" => Some(Self::Auto),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod pipeline_execution_service_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    #[derive(Debug, Clone)]
    pub struct PipelineExecutionServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl PipelineExecutionServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> PipelineExecutionServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> PipelineExecutionServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            PipelineExecutionServiceClient::new(
                InterceptedService::new(inner, interceptor),
            )
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Execute a pipeline with complete data input(s) and return all results
        ///
        /// This is a unary RPC: client sends one request, server sends one response.
        /// Suitable for batch processing and non-streaming use cases.
        ///
        /// Performance targets:
        ///
        /// * \<5ms latency for simple operations (SC-001)
        /// * \<10% serialization overhead (SC-003)
        /// * 10x faster than Python-based remote execution (SC-004)
        /// * \<5% overhead vs audio-only protocol for audio pipelines (SC-008)
        pub async fn execute_pipeline(
            &mut self,
            request: impl tonic::IntoRequest<super::ExecuteRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ExecuteResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/remotemedia.v1.PipelineExecutionService/ExecutePipeline",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "remotemedia.v1.PipelineExecutionService",
                        "ExecutePipeline",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Get service version and compatibility information
        ///
        /// Clients should call this on connection initialization to verify compatibility.
        pub async fn get_version(
            &mut self,
            request: impl tonic::IntoRequest<super::VersionRequest>,
        ) -> std::result::Result<
            tonic::Response<super::VersionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/remotemedia.v1.PipelineExecutionService/GetVersion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "remotemedia.v1.PipelineExecutionService",
                        "GetVersion",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Generated server implementations.
pub mod pipeline_execution_service_server {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with PipelineExecutionServiceServer.
    #[async_trait]
    pub trait PipelineExecutionService: std::marker::Send + std::marker::Sync + 'static {
        /// Execute a pipeline with complete data input(s) and return all results
        ///
        /// This is a unary RPC: client sends one request, server sends one response.
        /// Suitable for batch processing and non-streaming use cases.
        ///
        /// Performance targets:
        ///
        /// * \<5ms latency for simple operations (SC-001)
        /// * \<10% serialization overhead (SC-003)
        /// * 10x faster than Python-based remote execution (SC-004)
        /// * \<5% overhead vs audio-only protocol for audio pipelines (SC-008)
        async fn execute_pipeline(
            &self,
            request: tonic::Request<super::ExecuteRequest>,
        ) -> std::result::Result<tonic::Response<super::ExecuteResponse>, tonic::Status>;
        /// Get service version and compatibility information
        ///
        /// Clients should call this on connection initialization to verify compatibility.
        async fn get_version(
            &self,
            request: tonic::Request<super::VersionRequest>,
        ) -> std::result::Result<tonic::Response<super::VersionResponse>, tonic::Status>;
    }
    #[derive(Debug)]
    pub struct PipelineExecutionServiceServer<T> {
        inner: Arc<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    impl<T> PipelineExecutionServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>>
    for PipelineExecutionServiceServer<T>
    where
        T: PipelineExecutionService,
        B: Body + std::marker::Send + 'static,
        B::Error: Into<StdError> + std::marker::Send + 'static,
    {
        type Response = http::Response<tonic::body::Body>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            match req.uri().path() {
                "/remotemedia.v1.PipelineExecutionService/ExecutePipeline" => {
                    #[allow(non_camel_case_types)]
                    struct ExecutePipelineSvc<T: PipelineExecutionService>(pub Arc<T>);
                    impl<
                        T: PipelineExecutionService,
                    > tonic::server::UnaryService<super::ExecuteRequest>
                    for ExecutePipelineSvc<T> {
                        type Response = super::ExecuteResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::ExecuteRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as PipelineExecutionService>::execute_pipeline(
                                        &inner,
                                        request,
                                    )
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = ExecutePipelineSvc(inner);
                        let codec = tonic_prost::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/remotemedia.v1.PipelineExecutionService/GetVersion" => {
                    #[allow(non_camel_case_types)]
                    struct GetVersionSvc<T: PipelineExecutionService>(pub Arc<T>);
                    impl<
                        T: PipelineExecutionService,
                    > tonic::server::UnaryService<super::VersionRequest>
                    for GetVersionSvc<T> {
                        type Response = super::VersionResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::VersionRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as PipelineExecutionService>::get_version(
                                        &inner,
                                        request,
                                    )
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = GetVersionSvc(inner);
                        let codec = tonic_prost::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        let mut response = http::Response::new(
                            tonic::body::Body::default(),
                        );
                        let headers = response.headers_mut();
                        headers
                            .insert(
                                tonic::Status::GRPC_STATUS,
                                (tonic::Code::Unimplemented as i32).into(),
                            );
                        headers
                            .insert(
                                http::header::CONTENT_TYPE,
                                tonic::metadata::GRPC_CONTENT_TYPE,
                            );
                        Ok(response)
                    })
                }
            }
        }
    }
    impl<T> Clone for PipelineExecutionServiceServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    /// Generated gRPC service name
    pub const SERVICE_NAME: &str = "remotemedia.v1.PipelineExecutionService";
    impl<T> tonic::server::NamedService for PipelineExecutionServiceServer<T> {
        const NAME: &'static str = SERVICE_NAME;
    }
}
/// Client streaming request
///
/// UPDATED: Now supports both generic DataChunk and legacy AudioChunk
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamRequest {
    /// Request type (only one field set per message)
    #[prost(oneof = "stream_request::Request", tags = "1, 2, 3, 4")]
    pub request: ::core::option::Option<stream_request::Request>,
}
/// Nested message and enum types in `StreamRequest`.
pub mod stream_request {
    /// Request type (only one field set per message)
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Request {
        /// First message: pipeline initialization
        /// Must be sent before any data chunks
        #[prost(message, tag = "1")]
        Init(super::StreamInit),
        /// NEW: Generic data chunk (preferred, supports all data types)
        /// Use this for new implementations
        #[prost(message, tag = "2")]
        DataChunk(super::DataChunk),
        /// DEPRECATED: Legacy audio chunk (backward compatibility only)
        /// Server converts to DataChunk internally
        /// Will be removed in future version (6+ months)
        /// Migration: Use DataChunk with audio variant instead
        #[prost(message, tag = "3")]
        AudioChunk(super::AudioChunk),
        /// Control commands (close, cancel)
        #[prost(message, tag = "4")]
        Control(super::StreamControl),
    }
}
/// Initialize streaming pipeline (first message)
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamInit {
    /// Pipeline manifest
    #[prost(message, optional, tag = "1")]
    pub manifest: ::core::option::Option<PipelineManifest>,
    /// UPDATED: Generic initial data inputs (keyed by node ID)
    /// Replaces audio-only inputs from Feature 003
    /// Used for non-streaming initial state (e.g., config JSON)
    #[prost(map = "string, message", tag = "2")]
    pub data_inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        DataBuffer,
    >,
    /// Optional resource limits
    #[prost(message, optional, tag = "3")]
    pub resource_limits: ::core::option::Option<ResourceLimits>,
    /// Client protocol version
    #[prost(string, tag = "4")]
    pub client_version: ::prost::alloc::string::String,
    /// Expected chunk size hint
    /// For audio: samples per chunk
    /// For video: frames per chunk (usually 1)
    /// Helps service optimize buffer allocation
    #[prost(uint64, tag = "5")]
    pub expected_chunk_size: u64,
}
/// Generic streaming message that replaces AudioChunk
///
/// Carries any data type to any node. Supports both single-input and multi-input nodes.
///
/// Usage patterns:
///
/// Pattern 1: Single-input node (audio VAD)
/// DataChunk {
/// node_id: "vad",
/// buffer: DataBuffer { audio: { ... } },
/// sequence: 42,
/// timestamp_ms: 1000
/// }
///
/// Pattern 2: Multi-input node (audio + JSON control)
/// DataChunk {
/// node_id: "dynamic_filter",
/// named_buffers: {
/// "audio": DataBuffer { audio: { ... } },
/// "control": DataBuffer { json: { gain: 0.8 } }
/// },
/// sequence: 42,
/// timestamp_ms: 1000
/// }
///
/// Validation:
///
/// * Exactly one of buffer OR named_buffers must be set (not both, not neither)
/// * Sequence numbers must be strictly monotonic increasing
/// * Timestamps should be non-decreasing (warnings for inversions)
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DataChunk {
    /// Target node ID (must match manifest node)
    /// Must be a node that accepts streaming input
    #[prost(string, tag = "1")]
    pub node_id: ::prost::alloc::string::String,
    /// EITHER: Single unnamed buffer (for simple single-input nodes)
    /// Backward compatible with audio-only usage
    #[prost(message, optional, tag = "2")]
    pub buffer: ::core::option::Option<DataBuffer>,
    /// OR: Multiple named buffers (for multi-input nodes)
    /// Example: {"audio": audio_buffer, "control": json_buffer}
    /// Keys map to node input port names
    #[prost(map = "string, message", tag = "3")]
    pub named_buffers: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        DataBuffer,
    >,
    /// Sequence number for ordering (0, 1, 2, ...)
    /// Client increments for each chunk
    /// Server validates strict monotonic increase, detects gaps
    #[prost(uint64, tag = "4")]
    pub sequence: u64,
    /// Timestamp in milliseconds since stream start
    /// Used for synchronization and latency measurement
    #[prost(uint64, tag = "5")]
    pub timestamp_ms: u64,
}
/// DEPRECATED: Audio-only chunk message
///
/// Status: Maintained for backward compatibility with Feature 003 clients
/// Migration path: Use DataChunk with audio variant instead
/// Timeline: Will be removed after 6+ months deprecation period
///
/// Server implementation:
///
/// * Automatically converts AudioChunk → DataChunk at protocol boundary
/// * All internal logic uses generic DataChunk
/// * Zero logic duplication (single code path after conversion)
///
/// Conversion:
/// DataChunk {
/// node_id: AudioChunk.node_id,
/// buffer: DataBuffer { audio: AudioChunk.buffer },
/// sequence: AudioChunk.sequence,
/// timestamp_ms: AudioChunk.timestamp_ms
/// }
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct AudioChunk {
    /// Node ID to send this chunk to
    /// Must match a node in the manifest that accepts streaming input
    #[prost(string, tag = "1")]
    pub node_id: ::prost::alloc::string::String,
    /// Audio data for this chunk
    #[prost(message, optional, tag = "2")]
    pub buffer: ::core::option::Option<AudioBuffer>,
    /// Sequence number for ordering
    /// Client increments for each chunk (0, 1, 2, ...)
    /// Server uses this to detect out-of-order or missing chunks
    #[prost(uint64, tag = "3")]
    pub sequence: u64,
    /// Timestamp (milliseconds since stream start)
    /// Optional, used for synchronization in multi-stream scenarios
    #[prost(uint64, tag = "4")]
    pub timestamp_ms: u64,
}
/// Stream control commands (unchanged from Feature 003)
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamControl {
    /// Control command type
    #[prost(enumeration = "stream_control::Command", tag = "1")]
    pub command: i32,
}
/// Nested message and enum types in `StreamControl`.
pub mod stream_control {
    /// Control command enumeration
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Command {
        Unspecified = 0,
        /// Graceful close: flush pending chunks, return final results
        Close = 1,
        /// Abort execution: cancel immediately, discard pending data
        Cancel = 2,
    }
    impl Command {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "COMMAND_UNSPECIFIED",
                Self::Close => "COMMAND_CLOSE",
                Self::Cancel => "COMMAND_CANCEL",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "COMMAND_UNSPECIFIED" => Some(Self::Unspecified),
                "COMMAND_CLOSE" => Some(Self::Close),
                "COMMAND_CANCEL" => Some(Self::Cancel),
                _ => None,
            }
        }
    }
}
/// Server streaming response
///
/// UPDATED: ChunkResult now uses generic data outputs
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamResponse {
    /// Response type (only one field set per message)
    #[prost(oneof = "stream_response::Response", tags = "1, 2, 3, 4, 5")]
    pub response: ::core::option::Option<stream_response::Response>,
}
/// Nested message and enum types in `StreamResponse`.
pub mod stream_response {
    /// Response type (only one field set per message)
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Response {
        /// First response: pipeline ready to receive chunks
        #[prost(message, tag = "1")]
        Ready(super::StreamReady),
        /// Processed chunk result (one per input chunk)
        #[prost(message, tag = "2")]
        Result(super::ChunkResult),
        /// Error occurred during streaming
        #[prost(message, tag = "3")]
        Error(super::ErrorResponse),
        /// Periodic metrics update
        #[prost(message, tag = "4")]
        Metrics(super::StreamMetrics),
        /// Stream closed gracefully
        #[prost(message, tag = "5")]
        Closed(super::StreamClosed),
    }
}
/// Pipeline initialized and ready to receive chunks
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamReady {
    /// Unique session ID for this stream
    /// Client can use for correlation in logs
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,
    /// Server-recommended chunk size
    /// May differ from client's expected_chunk_size
    #[prost(uint64, tag = "2")]
    pub recommended_chunk_size: u64,
    /// Maximum buffer latency (milliseconds)
    /// Server will buffer up to this duration before processing
    #[prost(uint64, tag = "3")]
    pub max_buffer_latency_ms: u64,
}
/// Result from processing a single chunk
///
/// UPDATED: Uses generic data_outputs map (replaces audio_outputs + string data_outputs)
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChunkResult {
    /// Sequence number (matches input DataChunk.sequence)
    #[prost(uint64, tag = "1")]
    pub sequence: u64,
    /// UPDATED: Generic data outputs (keyed by node ID)
    /// Replaces separate audio_outputs and string data_outputs from Feature 003
    /// All output types now use DataBuffer
    ///
    /// Example (audio VAD):
    /// data_outputs: {
    /// "vad": DataBuffer { json: { has_speech: true, confidence: 0.87 } }
    /// }
    ///
    /// Example (audio filter):
    /// data_outputs: {
    /// "filter": DataBuffer { audio: { ... } }
    /// }
    #[prost(map = "string, message", tag = "2")]
    pub data_outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        DataBuffer,
    >,
    /// Processing latency for this chunk (milliseconds)
    /// Measured from chunk receipt to result ready
    #[prost(double, tag = "3")]
    pub processing_time_ms: f64,
    /// UPDATED: Cumulative items processed in this stream
    /// Generic count: samples (audio), frames (video), tokens (text), etc.
    /// Was: total_samples_processed in Feature 003
    #[prost(uint64, tag = "4")]
    pub total_items_processed: u64,
}
/// Periodic metrics update
///
/// Server sends these periodically (e.g., every 10 chunks) to provide
/// real-time visibility into stream health.
///
/// UPDATED: Uses generic item counting and type breakdown
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamMetrics {
    /// Session ID
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,
    /// Total chunks processed so far
    #[prost(uint64, tag = "2")]
    pub chunks_processed: u64,
    /// Average latency across all chunks (milliseconds)
    #[prost(double, tag = "3")]
    pub average_latency_ms: f64,
    /// UPDATED: Total items processed across all chunks
    /// Generic count: samples (audio), frames (video), tokens (text), etc.
    /// Was: total_samples in Feature 003
    #[prost(uint64, tag = "4")]
    pub total_items: u64,
    /// Current buffer occupancy (items)
    /// For audio: samples
    /// For video: frames
    #[prost(uint64, tag = "5")]
    pub buffer_items: u64,
    /// Number of chunks dropped (if any)
    #[prost(uint64, tag = "6")]
    pub chunks_dropped: u64,
    /// Peak memory usage for this stream (bytes)
    #[prost(uint64, tag = "7")]
    pub peak_memory_bytes: u64,
    /// NEW: Track data type distribution
    /// Keys: "audio", "video", "tensor", "json", "text", "binary"
    /// Values: Count of chunks processed per type
    ///
    /// Example:
    /// data_type_breakdown: {
    /// "audio": 80,  // 80 audio chunks
    /// "json": 20    // 20 JSON chunks (control parameters)
    /// }
    #[prost(map = "string, uint64", tag = "8")]
    pub data_type_breakdown: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        u64,
    >,
    /// Feature 005: Node cache metrics
    /// Total cache hits for this session
    #[prost(uint64, tag = "9")]
    pub cache_hits: u64,
    /// Total cache misses for this session
    #[prost(uint64, tag = "10")]
    pub cache_misses: u64,
    /// Number of nodes currently cached globally
    #[prost(uint64, tag = "11")]
    pub cached_nodes_count: u64,
    /// Cache hit rate (0.0 - 1.0)
    #[prost(double, tag = "12")]
    pub cache_hit_rate: f64,
}
/// Stream closed gracefully (unchanged from Feature 003)
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamClosed {
    /// Session ID
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,
    /// Final execution metrics
    #[prost(message, optional, tag = "2")]
    pub final_metrics: ::core::option::Option<ExecutionMetrics>,
    /// Reason for closure
    #[prost(string, tag = "3")]
    pub reason: ::prost::alloc::string::String,
}
/// Extended error response for streaming (unchanged from Feature 003)
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamErrorResponse {
    /// Base error information
    #[prost(message, optional, tag = "1")]
    pub base_error: ::core::option::Option<ErrorResponse>,
    /// Streaming-specific error type
    #[prost(enumeration = "StreamErrorType", tag = "2")]
    pub stream_error_type: i32,
    /// Sequence number where error occurred (if applicable)
    #[prost(uint64, tag = "3")]
    pub failing_sequence: u64,
    /// Session ID
    #[prost(string, tag = "4")]
    pub session_id: ::prost::alloc::string::String,
}
/// Streaming-specific error types (unchanged from Feature 003)
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum StreamErrorType {
    StreamErrorUnspecified = 0,
    /// Manifest not sent as first message
    StreamErrorInitRequired = 1,
    /// Invalid chunk sequence (gap or out-of-order)
    StreamErrorInvalidSequence = 2,
    /// Buffer overflow (client sending faster than server can process)
    StreamErrorBufferOverflow = 3,
    /// Stream timeout (no chunks received for X seconds)
    StreamErrorTimeout = 4,
    /// Client disconnected unexpectedly
    StreamErrorClientDisconnect = 5,
    /// Pipeline execution error during chunk processing
    StreamErrorExecution = 6,
}
impl StreamErrorType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::StreamErrorUnspecified => "STREAM_ERROR_UNSPECIFIED",
            Self::StreamErrorInitRequired => "STREAM_ERROR_INIT_REQUIRED",
            Self::StreamErrorInvalidSequence => "STREAM_ERROR_INVALID_SEQUENCE",
            Self::StreamErrorBufferOverflow => "STREAM_ERROR_BUFFER_OVERFLOW",
            Self::StreamErrorTimeout => "STREAM_ERROR_TIMEOUT",
            Self::StreamErrorClientDisconnect => "STREAM_ERROR_CLIENT_DISCONNECT",
            Self::StreamErrorExecution => "STREAM_ERROR_EXECUTION",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "STREAM_ERROR_UNSPECIFIED" => Some(Self::StreamErrorUnspecified),
            "STREAM_ERROR_INIT_REQUIRED" => Some(Self::StreamErrorInitRequired),
            "STREAM_ERROR_INVALID_SEQUENCE" => Some(Self::StreamErrorInvalidSequence),
            "STREAM_ERROR_BUFFER_OVERFLOW" => Some(Self::StreamErrorBufferOverflow),
            "STREAM_ERROR_TIMEOUT" => Some(Self::StreamErrorTimeout),
            "STREAM_ERROR_CLIENT_DISCONNECT" => Some(Self::StreamErrorClientDisconnect),
            "STREAM_ERROR_EXECUTION" => Some(Self::StreamErrorExecution),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod streaming_pipeline_service_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    #[derive(Debug, Clone)]
    pub struct StreamingPipelineServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl StreamingPipelineServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> StreamingPipelineServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> StreamingPipelineServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            StreamingPipelineServiceClient::new(
                InterceptedService::new(inner, interceptor),
            )
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Execute a pipeline with streaming data input/output
        ///
        /// This is a bidirectional streaming RPC:
        ///
        /// * Client sends: pipeline manifest (first message), then data chunks
        /// * Server sends: ready confirmation, then processing results per chunk
        ///
        /// Connection lifecycle:
        ///
        /// 1. Client sends manifest → Server validates and responds with StreamReady
        /// 1. Client sends data chunks → Server processes and responds with results
        /// 1. Client sends StreamControl::CLOSE → Server sends final metrics and closes
        ///
        /// Performance targets:
        ///
        /// * \<50ms average latency per chunk (User Story 3)
        /// * Support 1000+ concurrent streaming sessions (SC-002)
        /// * \<5% overhead vs audio-only protocol for audio pipelines (SC-008)
        pub async fn stream_pipeline(
            &mut self,
            request: impl tonic::IntoStreamingRequest<Message = super::StreamRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/remotemedia.v1.StreamingPipelineService/StreamPipeline",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "remotemedia.v1.StreamingPipelineService",
                        "StreamPipeline",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
    }
}
/// Generated server implementations.
pub mod streaming_pipeline_service_server {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with StreamingPipelineServiceServer.
    #[async_trait]
    pub trait StreamingPipelineService: std::marker::Send + std::marker::Sync + 'static {
        /// Server streaming response type for the StreamPipeline method.
        type StreamPipelineStream: tonic::codegen::tokio_stream::Stream<
                Item = std::result::Result<super::StreamResponse, tonic::Status>,
            >
            + std::marker::Send
            + 'static;
        /// Execute a pipeline with streaming data input/output
        ///
        /// This is a bidirectional streaming RPC:
        ///
        /// * Client sends: pipeline manifest (first message), then data chunks
        /// * Server sends: ready confirmation, then processing results per chunk
        ///
        /// Connection lifecycle:
        ///
        /// 1. Client sends manifest → Server validates and responds with StreamReady
        /// 1. Client sends data chunks → Server processes and responds with results
        /// 1. Client sends StreamControl::CLOSE → Server sends final metrics and closes
        ///
        /// Performance targets:
        ///
        /// * \<50ms average latency per chunk (User Story 3)
        /// * Support 1000+ concurrent streaming sessions (SC-002)
        /// * \<5% overhead vs audio-only protocol for audio pipelines (SC-008)
        async fn stream_pipeline(
            &self,
            request: tonic::Request<tonic::Streaming<super::StreamRequest>>,
        ) -> std::result::Result<
            tonic::Response<Self::StreamPipelineStream>,
            tonic::Status,
        >;
    }
    #[derive(Debug)]
    pub struct StreamingPipelineServiceServer<T> {
        inner: Arc<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    impl<T> StreamingPipelineServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>>
    for StreamingPipelineServiceServer<T>
    where
        T: StreamingPipelineService,
        B: Body + std::marker::Send + 'static,
        B::Error: Into<StdError> + std::marker::Send + 'static,
    {
        type Response = http::Response<tonic::body::Body>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            match req.uri().path() {
                "/remotemedia.v1.StreamingPipelineService/StreamPipeline" => {
                    #[allow(non_camel_case_types)]
                    struct StreamPipelineSvc<T: StreamingPipelineService>(pub Arc<T>);
                    impl<
                        T: StreamingPipelineService,
                    > tonic::server::StreamingService<super::StreamRequest>
                    for StreamPipelineSvc<T> {
                        type Response = super::StreamResponse;
                        type ResponseStream = T::StreamPipelineStream;
                        type Future = BoxFuture<
                            tonic::Response<Self::ResponseStream>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<
                                tonic::Streaming<super::StreamRequest>,
                            >,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as StreamingPipelineService>::stream_pipeline(
                                        &inner,
                                        request,
                                    )
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = StreamPipelineSvc(inner);
                        let codec = tonic_prost::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.streaming(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        let mut response = http::Response::new(
                            tonic::body::Body::default(),
                        );
                        let headers = response.headers_mut();
                        headers
                            .insert(
                                tonic::Status::GRPC_STATUS,
                                (tonic::Code::Unimplemented as i32).into(),
                            );
                        headers
                            .insert(
                                http::header::CONTENT_TYPE,
                                tonic::metadata::GRPC_CONTENT_TYPE,
                            );
                        Ok(response)
                    })
                }
            }
        }
    }
    impl<T> Clone for StreamingPipelineServiceServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    /// Generated gRPC service name
    pub const SERVICE_NAME: &str = "remotemedia.v1.StreamingPipelineService";
    impl<T> tonic::server::NamedService for StreamingPipelineServiceServer<T> {
        const NAME: &'static str = SERVICE_NAME;
    }
}
