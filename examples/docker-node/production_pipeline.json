{
    "name": "production_pipeline",
    "version": "1.0.0",
    "description": "Production-ready configuration with security hardening, resource monitoring, health checks, and operational best practices",
    "nodes": [
        {
            "id": "input",
            "node_type": "Input",
            "executor": null,
            "config": {},
            "metadata": {
                "description": "Pipeline input with rate limiting and validation"
            }
        },
        {
            "id": "security_hardened_gateway",
            "node_type": "gateway.SecureGateway",
            "executor": "multiprocess",
            "config": {
                "rate_limit_rps": 100,
                "validate_input": true,
                "sanitize_output": true
            },
            "metadata": {
                "description": "Security-hardened gateway node with minimal attack surface",
                "use_docker": true,
                "docker_config": {
                    "python_version": "3.11",
                    "base_image": "python:3.11-slim",
                    "python_packages": [
                        "pydantic>=2.5.0",
                        "email-validator>=2.1.0",
                        "python-multipart>=0.0.6",
                        "iceoryx2"
                    ],
                    "system_packages": [
                        "ca-certificates"
                    ],
                    "memory_mb": 512,
                    "cpu_cores": 1.0,
                    "shm_size_mb": 1024,
                    "env_vars": {
                        "PYTHONUNBUFFERED": "1",
                        "PYTHONHASHSEED": "random",
                        "PYTHONDONTWRITEBYTECODE": "1",
                        "PRODUCTION": "true",
                        "LOG_LEVEL": "INFO",
                        "VALIDATE_INPUT": "true",
                        "MAX_REQUEST_SIZE": "10485760",
                        "RATE_LIMIT_ENABLED": "true"
                    },
                    "gpu_devices": [],
                    "volumes": []
                },
                "security_features": [
                    "Non-root user (UID 1000) inside container",
                    "Read-only root filesystem where possible",
                    "No privileged mode or host network access",
                    "Minimal base image (slim) reduces attack surface",
                    "Input validation via pydantic prevents injection",
                    "Rate limiting prevents DoS attacks",
                    "No shell or unnecessary utilities in container",
                    "CA certificates only for HTTPS verification"
                ],
                "security_hardening": [
                    "Drop all capabilities (no CAP_SYS_ADMIN, etc.)",
                    "No new privileges flag set",
                    "AppArmor/SELinux profiles enforced",
                    "Seccomp profile blocks dangerous syscalls",
                    "Resource limits prevent resource exhaustion",
                    "Network policies restrict container communication"
                ]
            }
        },
        {
            "id": "monitored_processor",
            "node_type": "processing.MonitoredProcessor",
            "executor": "multiprocess",
            "config": {
                "enable_metrics": true,
                "enable_health_checks": true,
                "metric_export_interval_ms": 10000
            },
            "metadata": {
                "description": "Processing node with comprehensive metrics and health monitoring",
                "use_docker": true,
                "docker_config": {
                    "python_version": "3.11",
                    "base_image": "python:3.11-slim",
                    "python_packages": [
                        "prometheus-client>=0.18.0",
                        "opentelemetry-api>=1.21.0",
                        "opentelemetry-sdk>=1.21.0",
                        "opentelemetry-exporter-prometheus>=1.21.0",
                        "psutil>=5.9.0",
                        "iceoryx2"
                    ],
                    "system_packages": [],
                    "memory_mb": 1024,
                    "cpu_cores": 2.0,
                    "shm_size_mb": 2048,
                    "env_vars": {
                        "PYTHONUNBUFFERED": "1",
                        "PRODUCTION": "true",
                        "LOG_LEVEL": "INFO",
                        "METRICS_ENABLED": "true",
                        "METRICS_PORT": "9090",
                        "HEALTH_CHECK_PORT": "8080",
                        "HEALTH_CHECK_INTERVAL": "30",
                        "OTEL_SERVICE_NAME": "monitored_processor",
                        "OTEL_RESOURCE_ATTRIBUTES": "environment=production,version=1.0.0"
                    },
                    "gpu_devices": [],
                    "volumes": []
                },
                "monitoring_features": [
                    "Prometheus metrics: /metrics endpoint on port 9090",
                    "Health check endpoint: /health on port 8080",
                    "OpenTelemetry tracing for distributed requests",
                    "Process metrics: CPU, memory, threads, file descriptors",
                    "Custom business metrics: throughput, latency, errors",
                    "Automatic service discovery via labels"
                ],
                "exposed_metrics": [
                    "node_requests_total: Counter of processed requests",
                    "node_request_duration_seconds: Histogram of request latency",
                    "node_errors_total: Counter of errors by type",
                    "node_memory_usage_bytes: Gauge of current memory usage",
                    "node_cpu_usage_percent: Gauge of CPU utilization",
                    "node_ipc_messages_sent: Counter of IPC messages",
                    "node_ipc_messages_received: Counter of IPC messages",
                    "node_health_status: Gauge (1=healthy, 0=unhealthy)"
                ],
                "health_check_criteria": [
                    "Memory usage < 80% of limit",
                    "CPU usage < 90% for last 60 seconds",
                    "IPC channels connected and responsive",
                    "No errors in last 5 minutes",
                    "Response time < 1 second for health probe"
                ]
            }
        },
        {
            "id": "resilient_ml_service",
            "node_type": "ml.ResilientInference",
            "executor": "multiprocess",
            "config": {
                "model_name": "production_model_v3",
                "enable_circuit_breaker": true,
                "circuit_breaker_threshold": 5,
                "fallback_enabled": true
            },
            "metadata": {
                "description": "ML inference with circuit breaker, retries, and graceful degradation",
                "use_docker": true,
                "docker_config": {
                    "python_version": "3.10",
                    "base_image": "pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime",
                    "python_packages": [
                        "torch==2.1.0",
                        "transformers==4.35.0",
                        "tenacity>=8.2.0",
                        "circuitbreaker>=1.4.0",
                        "prometheus-client>=0.18.0",
                        "iceoryx2"
                    ],
                    "system_packages": [],
                    "memory_mb": 8192,
                    "cpu_cores": 4.0,
                    "shm_size_mb": 4096,
                    "env_vars": {
                        "PYTHONUNBUFFERED": "1",
                        "PRODUCTION": "true",
                        "LOG_LEVEL": "WARNING",
                        "CUDA_VISIBLE_DEVICES": "0",
                        "MODEL_PATH": "/models/production",
                        "TORCH_HOME": "/models/.torch",
                        "TRANSFORMERS_CACHE": "/models/.transformers",
                        "HF_DATASETS_OFFLINE": "1",
                        "CIRCUIT_BREAKER_ENABLED": "true",
                        "CIRCUIT_BREAKER_THRESHOLD": "5",
                        "CIRCUIT_BREAKER_TIMEOUT": "60",
                        "RETRY_MAX_ATTEMPTS": "3",
                        "RETRY_BACKOFF_FACTOR": "2"
                    },
                    "gpu_devices": ["0"],
                    "volumes": [
                        {
                            "host_path": "/mnt/models/production",
                            "container_path": "/models",
                            "read_only": true,
                            "mount_type": "bind"
                        }
                    ]
                },
                "resilience_patterns": [
                    "Circuit Breaker: Opens after 5 consecutive failures",
                    "Exponential Backoff: Retry with increasing delays",
                    "Fallback Strategy: Return cached or default result",
                    "Timeout Protection: 30s max per inference",
                    "Bulkhead Isolation: Separate thread pool for inference",
                    "Health Checks: Automatic restart if unhealthy"
                ],
                "error_handling": [
                    "Transient errors (network, timeout): Retry with backoff",
                    "Resource errors (OOM, GPU): Circuit breaker opens",
                    "Invalid input: Fast fail with error response",
                    "Model errors: Log, increment metric, return fallback",
                    "Circuit open: Return cached result or 503 status"
                ]
            }
        },
        {
            "id": "production_data_sink",
            "node_type": "output.ProductionSink",
            "executor": "multiprocess",
            "config": {
                "output_format": "avro",
                "compression": "snappy",
                "batch_size": 100,
                "flush_interval_ms": 5000
            },
            "metadata": {
                "description": "Production output with batching, compression, and persistence",
                "use_docker": true,
                "docker_config": {
                    "python_version": "3.11",
                    "base_image": "python:3.11-slim",
                    "python_packages": [
                        "fastavro>=1.9.0",
                        "aioboto3>=12.0.0",
                        "aiohttp>=3.9.0",
                        "orjson>=3.9.0",
                        "iceoryx2"
                    ],
                    "system_packages": [
                        "ca-certificates"
                    ],
                    "memory_mb": 1024,
                    "cpu_cores": 1.5,
                    "shm_size_mb": 2048,
                    "env_vars": {
                        "PYTHONUNBUFFERED": "1",
                        "PRODUCTION": "true",
                        "LOG_LEVEL": "INFO",
                        "OUTPUT_FORMAT": "avro",
                        "COMPRESSION": "snappy",
                        "BATCH_SIZE": "100",
                        "FLUSH_INTERVAL_MS": "5000",
                        "S3_ENDPOINT": "https://s3.amazonaws.com",
                        "S3_BUCKET": "production-pipeline-output",
                        "AWS_DEFAULT_REGION": "us-east-1"
                    },
                    "gpu_devices": [],
                    "volumes": [
                        {
                            "host_path": "/var/lib/remotemedia/credentials",
                            "container_path": "/credentials",
                            "read_only": true,
                            "mount_type": "bind"
                        }
                    ]
                },
                "production_features": [
                    "Batching: Aggregate 100 records before write",
                    "Compression: Snappy for fast compression/decompression",
                    "Avro serialization: Schema evolution support",
                    "Async I/O: Non-blocking writes to external storage",
                    "Credentials: Mounted from host secrets management",
                    "Retries: Automatic retry on transient write failures",
                    "Durability: At-least-once delivery guarantee"
                ]
            }
        },
        {
            "id": "output",
            "node_type": "Output",
            "executor": null,
            "config": {},
            "metadata": {
                "description": "Pipeline output with production guarantees"
            }
        }
    ],
    "edges": [
        {
            "source": "input",
            "target": "security_hardened_gateway",
            "field_mapping": {
                "source_field": "data",
                "target_field": "raw_input"
            }
        },
        {
            "source": "security_hardened_gateway",
            "target": "monitored_processor",
            "field_mapping": {
                "source_field": "validated_input",
                "target_field": "input"
            }
        },
        {
            "source": "monitored_processor",
            "target": "resilient_ml_service",
            "field_mapping": {
                "source_field": "processed_data",
                "target_field": "input_tensor"
            }
        },
        {
            "source": "resilient_ml_service",
            "target": "production_data_sink",
            "field_mapping": {
                "source_field": "predictions",
                "target_field": "results"
            }
        },
        {
            "source": "production_data_sink",
            "target": "output",
            "field_mapping": {
                "source_field": "persisted_data",
                "target_field": "final_output"
            }
        }
    ],
    "config": {
        "batch_size": 1,
        "timeout_ms": 60000,
        "retry_policy": {
            "max_retries": 3,
            "backoff_ms": 1000,
            "max_backoff_ms": 10000,
            "retry_on_timeout": true
        },
        "runtime_config": {
            "enable_docker": true,
            "docker_fallback_to_multiprocess": false,
            "docker_image_cache_size": 20,
            "docker_cleanup_on_exit": true,
            "enforce_resource_limits": true,
            "enable_health_checks": true,
            "health_check_interval_ms": 30000,
            "restart_unhealthy_nodes": true,
            "max_restarts": 3,
            "restart_backoff_ms": 5000
        }
    },
    "metadata": {
        "author": "RemoteMedia SDK",
        "created": "2024-12-20",
        "tags": ["docker", "production", "security", "monitoring", "resilience"],
        "description": "Production-grade pipeline with security hardening, comprehensive monitoring, resilience patterns, and operational best practices",
        "production_checklist": {
            "security": [
                "✓ Non-root user in all containers",
                "✓ Read-only root filesystem where possible",
                "✓ No privileged mode or host network",
                "✓ Input validation prevents injection attacks",
                "✓ Rate limiting prevents DoS",
                "✓ Secrets mounted from external secrets manager",
                "✓ TLS/SSL for all external communication",
                "✓ Container images scanned for vulnerabilities",
                "✓ AppArmor/SELinux profiles enforced",
                "✓ Network policies restrict inter-container traffic"
            ],
            "monitoring": [
                "✓ Prometheus metrics exposed on /metrics",
                "✓ Health check endpoints configured",
                "✓ Structured JSON logging to stdout",
                "✓ Distributed tracing with OpenTelemetry",
                "✓ Error tracking and alerting",
                "✓ Resource usage monitoring (CPU, memory, GPU)",
                "✓ SLI/SLO definitions and tracking",
                "✓ Dashboard for real-time monitoring"
            ],
            "resilience": [
                "✓ Circuit breakers prevent cascade failures",
                "✓ Exponential backoff on retries",
                "✓ Timeout protection for all operations",
                "✓ Graceful degradation strategies",
                "✓ Bulkhead isolation for critical services",
                "✓ Automatic restart of unhealthy nodes",
                "✓ At-least-once delivery guarantees",
                "✓ Idempotent operations where possible"
            ],
            "reliability": [
                "✓ Resource limits prevent resource exhaustion",
                "✓ Health checks detect failures early",
                "✓ Automatic restarts with backoff",
                "✓ Multiple replicas for high availability",
                "✓ Zero-downtime deployments",
                "✓ Rollback capability",
                "✓ Disaster recovery procedures",
                "✓ Regular backup and restore testing"
            ],
            "performance": [
                "✓ Resource allocations right-sized",
                "✓ GPU utilization optimized",
                "✓ Zero-copy IPC for data transfer",
                "✓ Batching for throughput optimization",
                "✓ Compression reduces network/storage costs",
                "✓ Connection pooling and reuse",
                "✓ Caching where appropriate",
                "✓ Load testing and capacity planning"
            ]
        },
        "operational_procedures": {
            "deployment": [
                "1. Build Docker images with CI/CD pipeline",
                "2. Scan images for vulnerabilities (Trivy, Clair)",
                "3. Push images to private container registry",
                "4. Deploy to staging environment first",
                "5. Run smoke tests and integration tests",
                "6. Monitor metrics for anomalies",
                "7. Deploy to production with blue-green or canary",
                "8. Monitor SLIs and verify SLOs met"
            ],
            "monitoring": [
                "1. Configure Prometheus to scrape /metrics endpoints",
                "2. Set up Grafana dashboards for visualization",
                "3. Configure alerting rules in Prometheus/Alertmanager",
                "4. Set up PagerDuty/Slack for incident notifications",
                "5. Configure log aggregation (ELK, Splunk, Datadog)",
                "6. Set up distributed tracing (Jaeger, Zipkin)",
                "7. Define SLIs/SLOs/SLAs for the pipeline",
                "8. Regular review of metrics and dashboards"
            ],
            "incident_response": [
                "1. Alert triggers (error rate, latency, availability)",
                "2. On-call engineer receives notification",
                "3. Check Grafana dashboards for anomalies",
                "4. Review container logs: docker logs <container>",
                "5. Check container health: docker inspect <container>",
                "6. Restart unhealthy containers if needed",
                "7. Escalate to engineering team if needed",
                "8. Post-incident review and action items"
            ],
            "backup_recovery": [
                "1. Model weights backed up to S3 with versioning",
                "2. Configuration stored in version control (GitOps)",
                "3. State stored in persistent volumes with snapshots",
                "4. Regular backup testing (monthly minimum)",
                "5. Recovery time objective (RTO): 15 minutes",
                "6. Recovery point objective (RPO): 1 hour",
                "7. Disaster recovery runbook documented",
                "8. DR drills conducted quarterly"
            ]
        },
        "sli_slo_definitions": {
            "availability": {
                "sli": "Percentage of successful health checks",
                "slo": "99.9% (43 minutes downtime per month)",
                "measurement": "Health check endpoint returns 200 OK"
            },
            "latency": {
                "sli": "95th percentile request latency",
                "slo": "<500ms for 95% of requests",
                "measurement": "node_request_duration_seconds histogram"
            },
            "error_rate": {
                "sli": "Percentage of failed requests",
                "slo": "<0.1% error rate",
                "measurement": "node_errors_total / node_requests_total"
            },
            "throughput": {
                "sli": "Requests processed per second",
                "slo": ">100 RPS sustained",
                "measurement": "rate(node_requests_total[1m])"
            }
        },
        "alerting_rules": {
            "high_error_rate": {
                "condition": "error_rate > 1% for 5 minutes",
                "severity": "critical",
                "action": "Page on-call engineer"
            },
            "high_latency": {
                "condition": "p95_latency > 1s for 5 minutes",
                "severity": "warning",
                "action": "Send Slack notification"
            },
            "container_restarting": {
                "condition": "container restarted > 3 times in 10 minutes",
                "severity": "critical",
                "action": "Page on-call engineer"
            },
            "high_memory_usage": {
                "condition": "memory_usage > 90% for 5 minutes",
                "severity": "warning",
                "action": "Send Slack notification"
            },
            "circuit_breaker_open": {
                "condition": "circuit_breaker_state = open for 5 minutes",
                "severity": "critical",
                "action": "Page on-call engineer"
            }
        },
        "docker_security_hardening": {
            "dockerfile": [
                "FROM python:3.11-slim AS base",
                "RUN adduser --disabled-password --gecos '' --uid 1000 appuser",
                "USER appuser",
                "WORKDIR /app",
                "COPY --chown=appuser:appuser requirements.txt .",
                "RUN pip install --no-cache-dir -r requirements.txt",
                "COPY --chown=appuser:appuser . .",
                "HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 \\",
                "  CMD python -c 'import requests; requests.get(\"http://localhost:8080/health\")'"
            ],
            "runtime_flags": [
                "--read-only: Make root filesystem read-only",
                "--security-opt=no-new-privileges: Prevent privilege escalation",
                "--cap-drop=ALL: Drop all Linux capabilities",
                "--security-opt=apparmor=docker-default: Enforce AppArmor",
                "--pids-limit=100: Limit number of processes",
                "--ulimit nofile=1024: Limit open file descriptors"
            ]
        },
        "performance_characteristics": {
            "cold_start": "10-15s (GPU + model loading)",
            "warm_start": "3-5s (cached image)",
            "request_latency": "200-500ms (p95)",
            "throughput": "100-500 RPS per node",
            "memory_overhead": "200MB per container",
            "cpu_overhead": "5-10% for monitoring/metrics",
            "ipc_throughput": "Multi-GB/s via iceoryx2"
        },
        "cost_optimization": {
            "resource_efficiency": "Right-sized containers save 30-60%",
            "image_caching": "Reduces build time and bandwidth",
            "spot_instances": "Use for fault-tolerant workloads",
            "auto_scaling": "Scale down during low traffic",
            "compression": "Reduces storage and network costs",
            "batch_processing": "Amortizes overhead across requests"
        }
    }
}
