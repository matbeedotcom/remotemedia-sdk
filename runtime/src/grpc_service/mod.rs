//! gRPC service implementation for high-performance remote pipeline execution
//!
//! This module provides a gRPC service that exposes the Rust runtime's audio pipeline
//! execution capabilities with <5ms latency and support for 1000+ concurrent connections.
//!
//! # Architecture
//!
//! - **server.rs**: Tonic server setup with middleware (auth, metrics, logging)
//! - **execution.rs**: Unary RPC handler for ExecutePipeline
//! - **streaming.rs**: Bidirectional streaming handler for StreamPipeline
//! - **auth.rs**: API token validation middleware
//! - **limits.rs**: Resource limit enforcement
//! - **metrics.rs**: Prometheus metrics collection
//! - **version.rs**: Protocol version negotiation
//!
//! # Protocol Buffers
//!
//! Generated from `runtime/protos/*.proto`:
//! - common.proto: AudioBuffer, ExecutionMetrics, ErrorResponse
//! - execution.proto: PipelineExecutionService, ExecutePipeline RPC
//! - streaming.proto: StreamingPipelineService, StreamPipeline RPC
//!
//! # Features
//!
//! This module is only compiled when the `grpc-transport` feature is enabled.

#![cfg(feature = "grpc-transport")]

// Submodules (implementation to be added in Phase 2 & 3)
pub mod auth;
pub mod execution;
pub mod limits;
pub mod metrics;
pub mod server;
pub mod streaming;
pub mod version;

// New async architecture modules
pub mod async_pipeline;
pub mod async_router;
pub mod session_router;

// Re-export generated protobuf types
// Generated by tonic-build in build.rs
pub mod generated {
    // Include generated code from build.rs output
    // build.rs writes to src/grpc_service/generated/
    include!("generated/remotemedia.v1.rs");
}

// Re-export key types for convenience
pub use generated::{
    AudioBuffer, AudioFormat, ErrorResponse, ErrorType, ExecutionMetrics, ExecutionStatus,
    NodeMetrics, NodeResult, NodeStatus, ResourceLimits, VersionInfo,
};

// Service traits
pub use generated::{
    pipeline_execution_service_server::{PipelineExecutionService, PipelineExecutionServiceServer},
    streaming_pipeline_service_server::{
        StreamingPipelineService, StreamingPipelineServiceServer,
    },
};

/// Error type for gRPC service operations
#[derive(Debug, thiserror::Error)]
pub enum ServiceError {
    #[error("Validation error: {0}")]
    Validation(String),

    #[error("Node execution error in {node_id}: {message}")]
    NodeExecution { node_id: String, message: String },

    #[error("Resource limit exceeded: {0}")]
    ResourceLimit(String),

    #[error("Authentication failed: {0}")]
    Authentication(String),

    #[error("Version mismatch: {0}")]
    VersionMismatch(String),

    #[error("Internal error: {0}")]
    Internal(String),
}

impl From<ServiceError> for tonic::Status {
    fn from(err: ServiceError) -> Self {
        use tonic::Code;
        match err {
            ServiceError::Validation(msg) => tonic::Status::new(Code::InvalidArgument, msg),
            ServiceError::NodeExecution { node_id, message } => {
                tonic::Status::new(Code::Internal, format!("Node {}: {}", node_id, message))
            }
            ServiceError::ResourceLimit(msg) => tonic::Status::new(Code::ResourceExhausted, msg),
            ServiceError::Authentication(msg) => tonic::Status::new(Code::Unauthenticated, msg),
            ServiceError::VersionMismatch(msg) => {
                tonic::Status::new(Code::FailedPrecondition, msg)
            }
            ServiceError::Internal(msg) => tonic::Status::new(Code::Internal, msg),
        }
    }
}

impl ServiceError {
    /// Convert to protobuf ErrorResponse
    pub fn to_proto(&self, node_id: Option<String>) -> ErrorResponse {
        let (error_type, message) = match self {
            ServiceError::Validation(msg) => (ErrorType::Validation as i32, msg.clone()),
            ServiceError::NodeExecution {
                node_id: _,
                message,
            } => (ErrorType::NodeExecution as i32, message.clone()),
            ServiceError::ResourceLimit(msg) => (ErrorType::ResourceLimit as i32, msg.clone()),
            ServiceError::Authentication(msg) => {
                (ErrorType::Authentication as i32, msg.clone())
            }
            ServiceError::VersionMismatch(msg) => {
                (ErrorType::VersionMismatch as i32, msg.clone())
            }
            ServiceError::Internal(msg) => (ErrorType::Internal as i32, msg.clone()),
        };

        ErrorResponse {
            error_type,
            message,
            failing_node_id: node_id.unwrap_or_default(),
            context: String::new(), // Will be populated by caller
            stack_trace: String::new(),
        }
    }
}

/// Service configuration
#[derive(Clone, Debug)]
pub struct ServiceConfig {
    /// Server bind address
    pub bind_address: String,
    
    /// Authentication configuration
    pub auth: auth::AuthConfig,
    
    /// Resource limits
    pub limits: limits::ResourceLimits,
    
    /// Version manager
    pub version: version::VersionManager,
    
    /// Enable JSON structured logging
    pub json_logging: bool,

    /// Preview feature: enable GPT-5 Codex behavior (metadata opt-in)
    ///
    /// Controlled by env var GPT5_CODEX_PREVIEW (true/false). Defaults to true so clients opting in via
    /// metadata "x-preview-features: gpt5-codex" are accepted. Set to false to deny preview requests.
    pub enable_gpt5_codex_preview: bool,
}

impl Default for ServiceConfig {
    fn default() -> Self {
        Self {
            bind_address: "[::1]:50051".to_string(), // IPv6 localhost
            auth: auth::AuthConfig::default(),
            limits: limits::ResourceLimits::default(),
            version: version::VersionManager::default(),
            json_logging: true,
            enable_gpt5_codex_preview: true,
        }
    }
}

impl ServiceConfig {
    /// Create from environment variables
    pub fn from_env() -> Self {
        let mut config = Self::default();
        
        // GRPC_BIND_ADDRESS="0.0.0.0:50051"
        if let Ok(addr) = std::env::var("GRPC_BIND_ADDRESS") {
            config.bind_address = addr;
        }
        
        // GRPC_AUTH_TOKENS="token1,token2,token3"
        if let Ok(tokens_str) = std::env::var("GRPC_AUTH_TOKENS") {
            let tokens: Vec<String> = tokens_str
                .split(',')
                .map(|s| s.trim().to_string())
                .filter(|s| !s.is_empty())
                .collect();
            config.auth = auth::AuthConfig::new(tokens, true);
        }
        
        // GRPC_REQUIRE_AUTH="false" (default: true)
        if let Ok(require_str) = std::env::var("GRPC_REQUIRE_AUTH") {
            if require_str.to_lowercase() == "false" {
                config.auth.require_auth = false;
            }
        }
        
        // GRPC_MAX_MEMORY_MB="200" (default: 100)
        if let Ok(mem_str) = std::env::var("GRPC_MAX_MEMORY_MB") {
            if let Ok(mem_mb) = mem_str.parse::<u64>() {
                config.limits.max_memory_bytes = mem_mb * 1_000_000;
            }
        }
        
        // GRPC_MAX_TIMEOUT_SEC="10" (default: 5)
        if let Ok(timeout_str) = std::env::var("GRPC_MAX_TIMEOUT_SEC") {
            if let Ok(timeout_sec) = timeout_str.parse::<u64>() {
                config.limits.max_timeout = std::time::Duration::from_secs(timeout_sec);
            }
        }
        
        // GRPC_JSON_LOGGING="false" (default: true)
        if let Ok(json_str) = std::env::var("GRPC_JSON_LOGGING") {
            config.json_logging = json_str.to_lowercase() != "false";
        }

        // GPT5_CODEX_PREVIEW="false" (default: true)
        // Also accept legacy/alternative name ENABLE_GPT5_CODEX_PREVIEW
        if let Ok(flag) = std::env::var("GPT5_CODEX_PREVIEW").or_else(|_| std::env::var("ENABLE_GPT5_CODEX_PREVIEW")) {
            let flag_lc = flag.to_lowercase();
            config.enable_gpt5_codex_preview = !(flag_lc == "false" || flag_lc == "0" || flag_lc == "off");
        }
        
        config
    }
}

/// Initialize tracing subscriber with JSON or pretty formatting
pub fn init_tracing(json_format: bool) {
    use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};
    
    if json_format {
        // JSON structured logging for production
        tracing_subscriber::registry()
            .with(
                tracing_subscriber::fmt::layer()
                    .json()
                    .with_current_span(true)
                    .with_span_list(true),
            )
            .with(tracing_subscriber::EnvFilter::from_default_env())
            .init();
    } else {
        // Pretty logging for development
        tracing_subscriber::registry()
            .with(
                tracing_subscriber::fmt::layer()
                    .pretty()
                    .with_line_number(true)
                    .with_thread_ids(true),
            )
            .with(tracing_subscriber::EnvFilter::from_default_env())
            .init();
    }
}
