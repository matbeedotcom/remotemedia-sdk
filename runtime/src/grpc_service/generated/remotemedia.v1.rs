// This file is @generated by prost-build.
/// Multi-channel audio data with sample rate and format metadata
///
/// Samples are stored in interleaved format for multi-channel audio.
/// For stereo: \[L0, R0, L1, R1, L2, R2, ...\]
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AudioBuffer {
    /// Raw audio samples (interleaved, little-endian)
    /// Size = num_samples * format.bytes_per_sample()
    #[prost(bytes = "vec", tag = "1")]
    pub samples: ::prost::alloc::vec::Vec<u8>,
    /// Sample rate in Hz (e.g., 8000, 16000, 44100, 48000)
    #[prost(uint32, tag = "2")]
    pub sample_rate: u32,
    /// Number of channels (1=mono, 2=stereo, 6=5.1 surround)
    #[prost(uint32, tag = "3")]
    pub channels: u32,
    /// Audio sample encoding format
    #[prost(enumeration = "AudioFormat", tag = "4")]
    pub format: i32,
    /// Total number of samples (including all channels)
    /// num_frames = num_samples / channels
    /// duration_seconds = num_frames / sample_rate
    #[prost(uint64, tag = "5")]
    pub num_samples: u64,
}
/// Performance metrics for pipeline execution
///
/// Tracks wall-clock time, CPU time, memory usage, and per-node statistics.
/// Used for performance monitoring and optimization.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutionMetrics {
    /// Wall-clock time from request receipt to response ready (milliseconds)
    /// Target: <5ms for simple operations (SC-001)
    #[prost(double, tag = "1")]
    pub wall_time_ms: f64,
    /// Total CPU time consumed by all threads (milliseconds)
    #[prost(double, tag = "2")]
    pub cpu_time_ms: f64,
    /// Peak memory usage during execution (bytes)
    /// Target: <10MB per concurrent execution (SC-008)
    #[prost(uint64, tag = "3")]
    pub memory_used_bytes: u64,
    /// Per-node execution statistics (keyed by node ID)
    #[prost(map = "string, message", tag = "4")]
    pub node_metrics: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        NodeMetrics,
    >,
    /// Time spent serializing/deserializing protobuf messages (milliseconds)
    /// Target: <10% of wall_time_ms (SC-003)
    #[prost(double, tag = "5")]
    pub serialization_time_ms: f64,
}
/// Performance metrics for a single node execution
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NodeMetrics {
    /// Time spent executing this node's process() method (milliseconds)
    #[prost(double, tag = "1")]
    pub execution_time_ms: f64,
    /// Memory allocated by this node (bytes)
    #[prost(uint64, tag = "2")]
    pub memory_bytes: u64,
    /// Total audio samples processed (across all channels)
    #[prost(uint64, tag = "3")]
    pub samples_processed: u64,
    /// Node-specific metrics (JSON encoded)
    /// Example: {"vad_segments": 12, "silence_ratio": 0.45}
    #[prost(string, tag = "4")]
    pub custom_metrics: ::prost::alloc::string::String,
}
/// Structured error information for debugging and diagnostics
///
/// Provides error category, message, context, and stack trace for
/// effective troubleshooting.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ErrorResponse {
    /// Error category for programmatic handling
    #[prost(enumeration = "ErrorType", tag = "1")]
    pub error_type: i32,
    /// Human-readable error message
    #[prost(string, tag = "2")]
    pub message: ::prost::alloc::string::String,
    /// Node ID where error occurred (empty for manifest validation errors)
    #[prost(string, tag = "3")]
    pub failing_node_id: ::prost::alloc::string::String,
    /// Execution context at time of error (JSON encoded)
    /// Example: {"input_sample_rate": 44100, "target_sample_rate": -1}
    #[prost(string, tag = "4")]
    pub context: ::prost::alloc::string::String,
    /// Rust panic stack trace (if available)
    #[prost(string, tag = "5")]
    pub stack_trace: ::prost::alloc::string::String,
}
/// Service version and protocol compatibility information
///
/// Returned by GetVersion() RPC to enable client compatibility checks.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VersionInfo {
    /// Current protocol version (e.g., "v1")
    #[prost(string, tag = "1")]
    pub protocol_version: ::prost::alloc::string::String,
    /// Rust runtime version (e.g., "0.2.1")
    #[prost(string, tag = "2")]
    pub runtime_version: ::prost::alloc::string::String,
    /// List of supported node types registered in this service
    /// Example: \["AudioResample", "VAD", "HFPipelineNode"\]
    #[prost(string, repeated, tag = "3")]
    pub supported_node_types: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// All protocol versions this service supports
    /// Example: \["v1"\] initially, may expand to \["v1", "v2"\]
    #[prost(string, repeated, tag = "4")]
    pub supported_protocols: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Service build timestamp (ISO 8601)
    /// Example: "2025-10-28T10:30:00Z"
    #[prost(string, tag = "5")]
    pub build_timestamp: ::prost::alloc::string::String,
}
/// Configurable resource constraints for pipeline execution
///
/// Clients can request custom limits within service-defined maximums.
/// Service applies defaults if not specified.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ResourceLimits {
    /// Maximum memory allocation (bytes)
    /// Default: 100MB, Max: 1GB (configurable per service)
    #[prost(uint64, tag = "1")]
    pub max_memory_bytes: u64,
    /// Maximum execution timeout (milliseconds)
    /// Default: 5000ms, Max: 30000ms (configurable per service)
    #[prost(uint64, tag = "2")]
    pub max_timeout_ms: u64,
    /// Maximum audio buffer size (samples, across all channels)
    /// Default: 10M samples (~200MB stereo F32)
    /// Prevents out-of-memory attacks
    #[prost(uint64, tag = "3")]
    pub max_audio_samples: u64,
}
/// Execution details for a single node
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NodeResult {
    /// Node ID from manifest
    #[prost(string, tag = "1")]
    pub node_id: ::prost::alloc::string::String,
    /// Execution status
    #[prost(enumeration = "NodeStatus", tag = "2")]
    pub status: i32,
    /// Error details (only if status == NODE_STATUS_FAILED)
    #[prost(message, optional, tag = "3")]
    pub error: ::core::option::Option<ErrorResponse>,
    /// Node-specific output metadata (JSON encoded)
    /// Example: {"output_format": "f32", "channels": 2}
    #[prost(string, tag = "4")]
    pub output_metadata: ::prost::alloc::string::String,
}
/// Audio sample encoding format
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum AudioFormat {
    Unspecified = 0,
    /// 32-bit floating point, range \[-1.0, 1.0\]
    /// 4 bytes per sample
    F32 = 1,
    /// 16-bit signed integer, range \[-32768, 32767\]
    /// 2 bytes per sample (most common format)
    I16 = 2,
    /// 32-bit signed integer
    /// 4 bytes per sample
    I32 = 3,
}
impl AudioFormat {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            AudioFormat::Unspecified => "AUDIO_FORMAT_UNSPECIFIED",
            AudioFormat::F32 => "AUDIO_FORMAT_F32",
            AudioFormat::I16 => "AUDIO_FORMAT_I16",
            AudioFormat::I32 => "AUDIO_FORMAT_I32",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "AUDIO_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
            "AUDIO_FORMAT_F32" => Some(Self::F32),
            "AUDIO_FORMAT_I16" => Some(Self::I16),
            "AUDIO_FORMAT_I32" => Some(Self::I32),
            _ => None,
        }
    }
}
/// Error category enumeration
///
/// Used by clients for error handling logic (retry, fix manifest, etc.)
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ErrorType {
    Unspecified = 0,
    /// Manifest validation error (malformed JSON, invalid node IDs, cycles)
    /// Action: Fix manifest and retry
    Validation = 1,
    /// Node execution failure (invalid parameters, processing error)
    /// Action: Check node parameters and input data
    NodeExecution = 2,
    /// Resource limit exceeded (memory, timeout, buffer size)
    /// Action: Reduce pipeline complexity or request higher limits
    ResourceLimit = 3,
    /// Authentication failed (invalid/missing API token)
    /// Action: Check API token configuration
    Authentication = 4,
    /// Protocol version mismatch (incompatible client/server versions)
    /// Action: Upgrade client library
    VersionMismatch = 5,
    /// Service internal error (panic, unexpected state)
    /// Action: Retry with exponential backoff, contact support if persistent
    Internal = 6,
}
impl ErrorType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            ErrorType::Unspecified => "ERROR_TYPE_UNSPECIFIED",
            ErrorType::Validation => "ERROR_TYPE_VALIDATION",
            ErrorType::NodeExecution => "ERROR_TYPE_NODE_EXECUTION",
            ErrorType::ResourceLimit => "ERROR_TYPE_RESOURCE_LIMIT",
            ErrorType::Authentication => "ERROR_TYPE_AUTHENTICATION",
            ErrorType::VersionMismatch => "ERROR_TYPE_VERSION_MISMATCH",
            ErrorType::Internal => "ERROR_TYPE_INTERNAL",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "ERROR_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "ERROR_TYPE_VALIDATION" => Some(Self::Validation),
            "ERROR_TYPE_NODE_EXECUTION" => Some(Self::NodeExecution),
            "ERROR_TYPE_RESOURCE_LIMIT" => Some(Self::ResourceLimit),
            "ERROR_TYPE_AUTHENTICATION" => Some(Self::Authentication),
            "ERROR_TYPE_VERSION_MISMATCH" => Some(Self::VersionMismatch),
            "ERROR_TYPE_INTERNAL" => Some(Self::Internal),
            _ => None,
        }
    }
}
/// Overall pipeline execution status
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ExecutionStatus {
    Unspecified = 0,
    /// All nodes executed successfully
    Success = 1,
    /// Some nodes were skipped but pipeline completed
    /// (e.g., conditional nodes based on input data)
    PartialSuccess = 2,
    /// Pipeline execution failed (see ErrorResponse for details)
    Failed = 3,
}
impl ExecutionStatus {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            ExecutionStatus::Unspecified => "EXECUTION_STATUS_UNSPECIFIED",
            ExecutionStatus::Success => "EXECUTION_STATUS_SUCCESS",
            ExecutionStatus::PartialSuccess => "EXECUTION_STATUS_PARTIAL_SUCCESS",
            ExecutionStatus::Failed => "EXECUTION_STATUS_FAILED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "EXECUTION_STATUS_UNSPECIFIED" => Some(Self::Unspecified),
            "EXECUTION_STATUS_SUCCESS" => Some(Self::Success),
            "EXECUTION_STATUS_PARTIAL_SUCCESS" => Some(Self::PartialSuccess),
            "EXECUTION_STATUS_FAILED" => Some(Self::Failed),
            _ => None,
        }
    }
}
/// Execution status for a single node
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum NodeStatus {
    Unspecified = 0,
    /// Node executed successfully
    Success = 1,
    /// Node was skipped (conditional execution)
    Skipped = 2,
    /// Node execution failed (see ErrorResponse for details)
    Failed = 3,
}
impl NodeStatus {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            NodeStatus::Unspecified => "NODE_STATUS_UNSPECIFIED",
            NodeStatus::Success => "NODE_STATUS_SUCCESS",
            NodeStatus::Skipped => "NODE_STATUS_SKIPPED",
            NodeStatus::Failed => "NODE_STATUS_FAILED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "NODE_STATUS_UNSPECIFIED" => Some(Self::Unspecified),
            "NODE_STATUS_SUCCESS" => Some(Self::Success),
            "NODE_STATUS_SKIPPED" => Some(Self::Skipped),
            "NODE_STATUS_FAILED" => Some(Self::Failed),
            _ => None,
        }
    }
}
/// Request to execute a pipeline
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteRequest {
    /// Pipeline manifest (JSON specification)
    #[prost(message, optional, tag = "1")]
    pub manifest: ::core::option::Option<PipelineManifest>,
    /// Input audio buffers (keyed by node ID)
    ///
    /// Example: {"audio_source": <AudioBuffer>}
    /// Node IDs must match nodes in the manifest that require audio input
    #[prost(map = "string, message", tag = "2")]
    pub audio_inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        AudioBuffer,
    >,
    /// Non-audio inputs (JSON encoded, keyed by node ID)
    ///
    /// Example: {"text_input": "{\"text\": \"Hello world\"}"}
    /// Used for text, embeddings, or other non-audio data
    #[prost(map = "string, string", tag = "3")]
    pub data_inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Optional resource limits for this execution
    /// If not specified, service applies default limits
    #[prost(message, optional, tag = "4")]
    pub resource_limits: ::core::option::Option<ResourceLimits>,
    /// Client protocol version (e.g., "v1")
    /// Service validates compatibility and returns ERROR_TYPE_VERSION_MISMATCH if incompatible
    #[prost(string, tag = "5")]
    pub client_version: ::prost::alloc::string::String,
}
/// Response from pipeline execution
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteResponse {
    /// Either result or error (mutually exclusive)
    #[prost(oneof = "execute_response::Outcome", tags = "1, 2")]
    pub outcome: ::core::option::Option<execute_response::Outcome>,
}
/// Nested message and enum types in `ExecuteResponse`.
pub mod execute_response {
    /// Either result or error (mutually exclusive)
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Outcome {
        /// Execution result (if successful)
        #[prost(message, tag = "1")]
        Result(super::ExecutionResult),
        /// Error details (if execution failed)
        #[prost(message, tag = "2")]
        Error(super::ErrorResponse),
    }
}
/// Pipeline manifest structure (v1)
///
/// Defines the processing graph: nodes (processing units) and
/// connections (data flow edges). Compatible with Rust runtime v0.2.1.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PipelineManifest {
    /// Schema version (e.g., "v1")
    /// Service validates this matches supported versions
    #[prost(string, tag = "1")]
    pub version: ::prost::alloc::string::String,
    /// Pipeline metadata
    #[prost(message, optional, tag = "2")]
    pub metadata: ::core::option::Option<ManifestMetadata>,
    /// List of processing nodes
    /// Must contain at least one node
    /// Node IDs must be unique
    #[prost(message, repeated, tag = "3")]
    pub nodes: ::prost::alloc::vec::Vec<NodeManifest>,
    /// Connections between nodes (directed edges)
    /// Forms a directed acyclic graph (DAG)
    #[prost(message, repeated, tag = "4")]
    pub connections: ::prost::alloc::vec::Vec<Connection>,
}
/// Pipeline metadata
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ManifestMetadata {
    /// Pipeline name (required)
    /// Used in logs and metrics
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional human-readable description
    #[prost(string, tag = "2")]
    pub description: ::prost::alloc::string::String,
    /// ISO 8601 timestamp of creation
    /// Example: "2025-10-28T10:30:00Z"
    #[prost(string, tag = "3")]
    pub created_at: ::prost::alloc::string::String,
}
/// Node manifest entry
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NodeManifest {
    /// Unique node ID within pipeline
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Node type (class name)
    /// Example: "AudioResample", "VAD", "HFPipelineNode"
    /// Service validates against registered node types
    #[prost(string, tag = "2")]
    pub node_type: ::prost::alloc::string::String,
    /// Node-specific parameters (JSON encoded)
    /// Service deserializes into serde_json::Value
    /// Example: "{\"target_sample_rate\": 16000}"
    #[prost(string, tag = "3")]
    pub params: ::prost::alloc::string::String,
    /// Whether node uses streaming (async generator)
    /// If true, node's process() method is an async generator
    #[prost(bool, tag = "4")]
    pub is_streaming: bool,
    /// Optional capability requirements (GPU, CPU, memory)
    #[prost(message, optional, tag = "5")]
    pub capabilities: ::core::option::Option<CapabilityRequirements>,
    /// Optional execution host preference (reserved for future)
    #[prost(string, tag = "6")]
    pub host: ::prost::alloc::string::String,
    /// Optional runtime hint for Python nodes
    #[prost(enumeration = "RuntimeHint", tag = "7")]
    pub runtime_hint: i32,
}
/// Connection between nodes
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Connection {
    /// Source node ID (produces output)
    #[prost(string, tag = "1")]
    pub from: ::prost::alloc::string::String,
    /// Target node ID (consumes input)
    #[prost(string, tag = "2")]
    pub to: ::prost::alloc::string::String,
}
/// Hardware/resource requirements for node execution
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CapabilityRequirements {
    /// GPU requirements
    #[prost(message, optional, tag = "1")]
    pub gpu: ::core::option::Option<GpuRequirement>,
    /// CPU requirements
    #[prost(message, optional, tag = "2")]
    pub cpu: ::core::option::Option<CpuRequirement>,
    /// Memory requirement (gigabytes)
    #[prost(double, tag = "3")]
    pub memory_gb: f64,
}
/// GPU hardware requirements
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GpuRequirement {
    /// GPU type: "cuda", "rocm", "metal"
    #[prost(string, tag = "1")]
    pub r#type: ::prost::alloc::string::String,
    /// Minimum GPU memory (GB)
    #[prost(double, tag = "2")]
    pub min_memory_gb: f64,
    /// Whether GPU is required or optional
    #[prost(bool, tag = "3")]
    pub required: bool,
}
/// CPU requirements
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CpuRequirement {
    /// Minimum number of cores
    #[prost(uint32, tag = "1")]
    pub cores: u32,
    /// CPU architecture preference
    /// Example: "x86_64", "aarch64"
    #[prost(string, tag = "2")]
    pub arch: ::prost::alloc::string::String,
}
/// Result of successful pipeline execution
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutionResult {
    /// Processed audio outputs (keyed by node ID)
    /// Empty map for pipelines with no audio outputs
    #[prost(map = "string, message", tag = "1")]
    pub audio_outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        AudioBuffer,
    >,
    /// Non-audio outputs (JSON encoded, keyed by node ID)
    /// Example: {"transcribe": "{\"text\": \"Hello world\", \"confidence\": 0.95}"}
    #[prost(map = "string, string", tag = "2")]
    pub data_outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Execution performance metrics
    #[prost(message, optional, tag = "3")]
    pub metrics: ::core::option::Option<ExecutionMetrics>,
    /// Per-node execution results
    #[prost(message, repeated, tag = "4")]
    pub node_results: ::prost::alloc::vec::Vec<NodeResult>,
    /// Overall execution status
    #[prost(enumeration = "ExecutionStatus", tag = "5")]
    pub status: i32,
}
/// Request for version information
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VersionRequest {
    /// Client version for compatibility check (e.g., "v1", "v1.2.0")
    #[prost(string, tag = "1")]
    pub client_version: ::prost::alloc::string::String,
}
/// Response with version and compatibility information
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VersionResponse {
    /// Service version details
    #[prost(message, optional, tag = "1")]
    pub version_info: ::core::option::Option<VersionInfo>,
    /// Whether client version is compatible
    #[prost(bool, tag = "2")]
    pub compatible: bool,
    /// Compatibility message (details if incompatible)
    /// Example: "Client v2 requires service v0.3.0+"
    #[prost(string, tag = "3")]
    pub compatibility_message: ::prost::alloc::string::String,
}
/// Runtime hint for Python node execution
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum RuntimeHint {
    Unspecified = 0,
    /// Use RustPython embedded interpreter (pure Rust, limited stdlib)
    Rustpython = 1,
    /// Use CPython via PyO3 in-process (full Python ecosystem, C-extensions)
    Cpython = 2,
    /// Use CPython compiled to WASM (sandboxed, Phase 3)
    CpythonWasm = 3,
    /// Automatically select runtime based on node requirements
    Auto = 4,
}
impl RuntimeHint {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            RuntimeHint::Unspecified => "RUNTIME_HINT_UNSPECIFIED",
            RuntimeHint::Rustpython => "RUNTIME_HINT_RUSTPYTHON",
            RuntimeHint::Cpython => "RUNTIME_HINT_CPYTHON",
            RuntimeHint::CpythonWasm => "RUNTIME_HINT_CPYTHON_WASM",
            RuntimeHint::Auto => "RUNTIME_HINT_AUTO",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "RUNTIME_HINT_UNSPECIFIED" => Some(Self::Unspecified),
            "RUNTIME_HINT_RUSTPYTHON" => Some(Self::Rustpython),
            "RUNTIME_HINT_CPYTHON" => Some(Self::Cpython),
            "RUNTIME_HINT_CPYTHON_WASM" => Some(Self::CpythonWasm),
            "RUNTIME_HINT_AUTO" => Some(Self::Auto),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod pipeline_execution_service_client {
    #![allow(unused_variables, dead_code, missing_docs, clippy::let_unit_value)]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    #[derive(Debug, Clone)]
    pub struct PipelineExecutionServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl PipelineExecutionServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> PipelineExecutionServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::BoxBody>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> PipelineExecutionServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::BoxBody>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
            >>::Error: Into<StdError> + Send + Sync,
        {
            PipelineExecutionServiceClient::new(
                InterceptedService::new(inner, interceptor),
            )
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Execute a pipeline with complete audio input(s) and return all results
        ///
        /// This is a unary RPC: client sends one request, server sends one response.
        /// Suitable for batch processing and non-streaming use cases.
        ///
        /// Performance targets:
        /// - <5ms latency for simple operations (SC-001)
        /// - <10% serialization overhead (SC-003)
        /// - 10x faster than Python-based remote execution (SC-004)
        pub async fn execute_pipeline(
            &mut self,
            request: impl tonic::IntoRequest<super::ExecuteRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ExecuteResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/remotemedia.v1.PipelineExecutionService/ExecutePipeline",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "remotemedia.v1.PipelineExecutionService",
                        "ExecutePipeline",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Get service version and compatibility information
        ///
        /// Clients should call this on connection initialization to verify compatibility.
        pub async fn get_version(
            &mut self,
            request: impl tonic::IntoRequest<super::VersionRequest>,
        ) -> std::result::Result<
            tonic::Response<super::VersionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/remotemedia.v1.PipelineExecutionService/GetVersion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "remotemedia.v1.PipelineExecutionService",
                        "GetVersion",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Generated server implementations.
pub mod pipeline_execution_service_server {
    #![allow(unused_variables, dead_code, missing_docs, clippy::let_unit_value)]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with PipelineExecutionServiceServer.
    #[async_trait]
    pub trait PipelineExecutionService: Send + Sync + 'static {
        /// Execute a pipeline with complete audio input(s) and return all results
        ///
        /// This is a unary RPC: client sends one request, server sends one response.
        /// Suitable for batch processing and non-streaming use cases.
        ///
        /// Performance targets:
        /// - <5ms latency for simple operations (SC-001)
        /// - <10% serialization overhead (SC-003)
        /// - 10x faster than Python-based remote execution (SC-004)
        async fn execute_pipeline(
            &self,
            request: tonic::Request<super::ExecuteRequest>,
        ) -> std::result::Result<tonic::Response<super::ExecuteResponse>, tonic::Status>;
        /// Get service version and compatibility information
        ///
        /// Clients should call this on connection initialization to verify compatibility.
        async fn get_version(
            &self,
            request: tonic::Request<super::VersionRequest>,
        ) -> std::result::Result<tonic::Response<super::VersionResponse>, tonic::Status>;
    }
    #[derive(Debug)]
    pub struct PipelineExecutionServiceServer<T: PipelineExecutionService> {
        inner: _Inner<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    struct _Inner<T>(Arc<T>);
    impl<T: PipelineExecutionService> PipelineExecutionServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            let inner = _Inner(inner);
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>>
    for PipelineExecutionServiceServer<T>
    where
        T: PipelineExecutionService,
        B: Body + Send + 'static,
        B::Error: Into<StdError> + Send + 'static,
    {
        type Response = http::Response<tonic::body::BoxBody>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            let inner = self.inner.clone();
            match req.uri().path() {
                "/remotemedia.v1.PipelineExecutionService/ExecutePipeline" => {
                    #[allow(non_camel_case_types)]
                    struct ExecutePipelineSvc<T: PipelineExecutionService>(pub Arc<T>);
                    impl<
                        T: PipelineExecutionService,
                    > tonic::server::UnaryService<super::ExecuteRequest>
                    for ExecutePipelineSvc<T> {
                        type Response = super::ExecuteResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::ExecuteRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as PipelineExecutionService>::execute_pipeline(
                                        &inner,
                                        request,
                                    )
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = ExecutePipelineSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/remotemedia.v1.PipelineExecutionService/GetVersion" => {
                    #[allow(non_camel_case_types)]
                    struct GetVersionSvc<T: PipelineExecutionService>(pub Arc<T>);
                    impl<
                        T: PipelineExecutionService,
                    > tonic::server::UnaryService<super::VersionRequest>
                    for GetVersionSvc<T> {
                        type Response = super::VersionResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::VersionRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as PipelineExecutionService>::get_version(
                                        &inner,
                                        request,
                                    )
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = GetVersionSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        Ok(
                            http::Response::builder()
                                .status(200)
                                .header("grpc-status", "12")
                                .header("content-type", "application/grpc")
                                .body(empty_body())
                                .unwrap(),
                        )
                    })
                }
            }
        }
    }
    impl<T: PipelineExecutionService> Clone for PipelineExecutionServiceServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    impl<T: PipelineExecutionService> Clone for _Inner<T> {
        fn clone(&self) -> Self {
            Self(Arc::clone(&self.0))
        }
    }
    impl<T: std::fmt::Debug> std::fmt::Debug for _Inner<T> {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            write!(f, "{:?}", self.0)
        }
    }
    impl<T: PipelineExecutionService> tonic::server::NamedService
    for PipelineExecutionServiceServer<T> {
        const NAME: &'static str = "remotemedia.v1.PipelineExecutionService";
    }
}
/// Client streaming request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamRequest {
    /// Request type (only one field set per message)
    #[prost(oneof = "stream_request::Request", tags = "1, 2, 3")]
    pub request: ::core::option::Option<stream_request::Request>,
}
/// Nested message and enum types in `StreamRequest`.
pub mod stream_request {
    /// Request type (only one field set per message)
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Request {
        /// First message: pipeline initialization
        /// Must be sent before any audio chunks
        #[prost(message, tag = "1")]
        Init(super::StreamInit),
        /// Subsequent messages: audio data chunks
        #[prost(message, tag = "2")]
        AudioChunk(super::AudioChunk),
        /// Control commands (close, cancel)
        #[prost(message, tag = "3")]
        Control(super::StreamControl),
    }
}
/// Initialize streaming pipeline (first message)
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamInit {
    /// Pipeline manifest
    #[prost(message, optional, tag = "1")]
    pub manifest: ::core::option::Option<PipelineManifest>,
    /// Initial non-audio inputs (JSON encoded, keyed by node ID)
    #[prost(map = "string, string", tag = "2")]
    pub data_inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Optional resource limits
    #[prost(message, optional, tag = "3")]
    pub resource_limits: ::core::option::Option<ResourceLimits>,
    /// Client protocol version
    #[prost(string, tag = "4")]
    pub client_version: ::prost::alloc::string::String,
    /// Expected chunk size (samples per chunk)
    /// Helps service optimize buffer allocation
    #[prost(uint64, tag = "5")]
    pub expected_chunk_size: u64,
}
/// Audio data chunk
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AudioChunk {
    /// Node ID to send this chunk to
    /// Must match a node in the manifest that accepts streaming input
    #[prost(string, tag = "1")]
    pub node_id: ::prost::alloc::string::String,
    /// Audio data for this chunk
    #[prost(message, optional, tag = "2")]
    pub buffer: ::core::option::Option<AudioBuffer>,
    /// Sequence number for ordering
    /// Client increments for each chunk (0, 1, 2, ...)
    /// Server uses this to detect out-of-order or missing chunks
    #[prost(uint64, tag = "3")]
    pub sequence: u64,
    /// Timestamp (milliseconds since stream start)
    /// Optional, used for synchronization in multi-stream scenarios
    #[prost(uint64, tag = "4")]
    pub timestamp_ms: u64,
}
/// Stream control commands
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamControl {
    /// Control command type
    #[prost(enumeration = "stream_control::Command", tag = "1")]
    pub command: i32,
}
/// Nested message and enum types in `StreamControl`.
pub mod stream_control {
    /// Control command enumeration
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Command {
        Unspecified = 0,
        /// Graceful close: flush pending chunks, return final results
        Close = 1,
        /// Abort execution: cancel immediately, discard pending data
        Cancel = 2,
    }
    impl Command {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Command::Unspecified => "COMMAND_UNSPECIFIED",
                Command::Close => "COMMAND_CLOSE",
                Command::Cancel => "COMMAND_CANCEL",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "COMMAND_UNSPECIFIED" => Some(Self::Unspecified),
                "COMMAND_CLOSE" => Some(Self::Close),
                "COMMAND_CANCEL" => Some(Self::Cancel),
                _ => None,
            }
        }
    }
}
/// Server streaming response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamResponse {
    /// Response type (only one field set per message)
    #[prost(oneof = "stream_response::Response", tags = "1, 2, 3, 4, 5")]
    pub response: ::core::option::Option<stream_response::Response>,
}
/// Nested message and enum types in `StreamResponse`.
pub mod stream_response {
    /// Response type (only one field set per message)
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Response {
        /// First response: pipeline ready to receive chunks
        #[prost(message, tag = "1")]
        Ready(super::StreamReady),
        /// Processed chunk result (one per input chunk)
        #[prost(message, tag = "2")]
        Result(super::ChunkResult),
        /// Error occurred during streaming
        #[prost(message, tag = "3")]
        Error(super::ErrorResponse),
        /// Periodic metrics update
        #[prost(message, tag = "4")]
        Metrics(super::StreamMetrics),
        /// Stream closed gracefully
        #[prost(message, tag = "5")]
        Closed(super::StreamClosed),
    }
}
/// Pipeline initialized and ready to receive chunks
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamReady {
    /// Unique session ID for this stream
    /// Client can use for correlation in logs
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,
    /// Server-recommended chunk size (samples)
    /// May differ from client's expected_chunk_size
    #[prost(uint64, tag = "2")]
    pub recommended_chunk_size: u64,
    /// Maximum buffer latency (milliseconds)
    /// Server will buffer up to this duration before processing
    #[prost(uint64, tag = "3")]
    pub max_buffer_latency_ms: u64,
}
/// Result from processing a single chunk
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChunkResult {
    /// Sequence number (matches input AudioChunk.sequence)
    #[prost(uint64, tag = "1")]
    pub sequence: u64,
    /// Processed audio outputs (keyed by node ID)
    #[prost(map = "string, message", tag = "2")]
    pub audio_outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        AudioBuffer,
    >,
    /// Non-audio outputs (JSON, keyed by node ID)
    /// Example: VAD result: {"has_speech": true, "confidence": 0.87}
    #[prost(map = "string, string", tag = "3")]
    pub data_outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Processing latency for this chunk (milliseconds)
    /// Measured from chunk receipt to result ready
    #[prost(double, tag = "4")]
    pub processing_time_ms: f64,
    /// Cumulative samples processed in this stream
    #[prost(uint64, tag = "5")]
    pub total_samples_processed: u64,
}
/// Periodic metrics update
///
/// Server sends these periodically (e.g., every 10 chunks) to provide
/// real-time visibility into stream health.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamMetrics {
    /// Session ID
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,
    /// Total chunks processed so far
    #[prost(uint64, tag = "2")]
    pub chunks_processed: u64,
    /// Average latency across all chunks (milliseconds)
    #[prost(double, tag = "3")]
    pub average_latency_ms: f64,
    /// Total samples processed across all chunks
    #[prost(uint64, tag = "4")]
    pub total_samples: u64,
    /// Current buffer occupancy (samples)
    #[prost(uint64, tag = "5")]
    pub buffer_samples: u64,
    /// Number of chunks dropped (if any)
    #[prost(uint64, tag = "6")]
    pub chunks_dropped: u64,
    /// Peak memory usage for this stream (bytes)
    #[prost(uint64, tag = "7")]
    pub peak_memory_bytes: u64,
}
/// Stream closed gracefully
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamClosed {
    /// Session ID
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,
    /// Final execution metrics
    #[prost(message, optional, tag = "2")]
    pub final_metrics: ::core::option::Option<ExecutionMetrics>,
    /// Reason for closure
    #[prost(string, tag = "3")]
    pub reason: ::prost::alloc::string::String,
}
/// Extended error response for streaming
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamErrorResponse {
    /// Base error information
    #[prost(message, optional, tag = "1")]
    pub base_error: ::core::option::Option<ErrorResponse>,
    /// Streaming-specific error type
    #[prost(enumeration = "StreamErrorType", tag = "2")]
    pub stream_error_type: i32,
    /// Sequence number where error occurred (if applicable)
    #[prost(uint64, tag = "3")]
    pub failing_sequence: u64,
    /// Session ID
    #[prost(string, tag = "4")]
    pub session_id: ::prost::alloc::string::String,
}
/// Streaming-specific error types
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum StreamErrorType {
    StreamErrorUnspecified = 0,
    /// Manifest not sent as first message
    StreamErrorInitRequired = 1,
    /// Invalid chunk sequence (gap or out-of-order)
    StreamErrorInvalidSequence = 2,
    /// Buffer overflow (client sending faster than server can process)
    StreamErrorBufferOverflow = 3,
    /// Stream timeout (no chunks received for X seconds)
    StreamErrorTimeout = 4,
    /// Client disconnected unexpectedly
    StreamErrorClientDisconnect = 5,
    /// Pipeline execution error during chunk processing
    StreamErrorExecution = 6,
}
impl StreamErrorType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            StreamErrorType::StreamErrorUnspecified => "STREAM_ERROR_UNSPECIFIED",
            StreamErrorType::StreamErrorInitRequired => "STREAM_ERROR_INIT_REQUIRED",
            StreamErrorType::StreamErrorInvalidSequence => {
                "STREAM_ERROR_INVALID_SEQUENCE"
            }
            StreamErrorType::StreamErrorBufferOverflow => "STREAM_ERROR_BUFFER_OVERFLOW",
            StreamErrorType::StreamErrorTimeout => "STREAM_ERROR_TIMEOUT",
            StreamErrorType::StreamErrorClientDisconnect => {
                "STREAM_ERROR_CLIENT_DISCONNECT"
            }
            StreamErrorType::StreamErrorExecution => "STREAM_ERROR_EXECUTION",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "STREAM_ERROR_UNSPECIFIED" => Some(Self::StreamErrorUnspecified),
            "STREAM_ERROR_INIT_REQUIRED" => Some(Self::StreamErrorInitRequired),
            "STREAM_ERROR_INVALID_SEQUENCE" => Some(Self::StreamErrorInvalidSequence),
            "STREAM_ERROR_BUFFER_OVERFLOW" => Some(Self::StreamErrorBufferOverflow),
            "STREAM_ERROR_TIMEOUT" => Some(Self::StreamErrorTimeout),
            "STREAM_ERROR_CLIENT_DISCONNECT" => Some(Self::StreamErrorClientDisconnect),
            "STREAM_ERROR_EXECUTION" => Some(Self::StreamErrorExecution),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod streaming_pipeline_service_client {
    #![allow(unused_variables, dead_code, missing_docs, clippy::let_unit_value)]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    #[derive(Debug, Clone)]
    pub struct StreamingPipelineServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl StreamingPipelineServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> StreamingPipelineServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::BoxBody>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> StreamingPipelineServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::BoxBody>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
            >>::Error: Into<StdError> + Send + Sync,
        {
            StreamingPipelineServiceClient::new(
                InterceptedService::new(inner, interceptor),
            )
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Execute a pipeline with streaming audio input/output
        ///
        /// This is a bidirectional streaming RPC:
        /// - Client sends: pipeline manifest (first message), then audio chunks
        /// - Server sends: ready confirmation, then processing results per chunk
        ///
        /// Connection lifecycle:
        /// 1. Client sends manifest  Server validates and responds with StreamReady
        /// 2. Client sends audio chunks  Server processes and responds with results
        /// 3. Client sends StreamControl::CLOSE  Server sends final metrics and closes
        ///
        /// Performance targets:
        /// - <50ms average latency per chunk (User Story 3)
        /// - Support 1000+ concurrent streaming sessions (SC-002)
        pub async fn stream_pipeline(
            &mut self,
            request: impl tonic::IntoStreamingRequest<Message = super::StreamRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/remotemedia.v1.StreamingPipelineService/StreamPipeline",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "remotemedia.v1.StreamingPipelineService",
                        "StreamPipeline",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
    }
}
/// Generated server implementations.
pub mod streaming_pipeline_service_server {
    #![allow(unused_variables, dead_code, missing_docs, clippy::let_unit_value)]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with StreamingPipelineServiceServer.
    #[async_trait]
    pub trait StreamingPipelineService: Send + Sync + 'static {
        /// Server streaming response type for the StreamPipeline method.
        type StreamPipelineStream: tonic::codegen::tokio_stream::Stream<
                Item = std::result::Result<super::StreamResponse, tonic::Status>,
            >
            + Send
            + 'static;
        /// Execute a pipeline with streaming audio input/output
        ///
        /// This is a bidirectional streaming RPC:
        /// - Client sends: pipeline manifest (first message), then audio chunks
        /// - Server sends: ready confirmation, then processing results per chunk
        ///
        /// Connection lifecycle:
        /// 1. Client sends manifest  Server validates and responds with StreamReady
        /// 2. Client sends audio chunks  Server processes and responds with results
        /// 3. Client sends StreamControl::CLOSE  Server sends final metrics and closes
        ///
        /// Performance targets:
        /// - <50ms average latency per chunk (User Story 3)
        /// - Support 1000+ concurrent streaming sessions (SC-002)
        async fn stream_pipeline(
            &self,
            request: tonic::Request<tonic::Streaming<super::StreamRequest>>,
        ) -> std::result::Result<
            tonic::Response<Self::StreamPipelineStream>,
            tonic::Status,
        >;
    }
    #[derive(Debug)]
    pub struct StreamingPipelineServiceServer<T: StreamingPipelineService> {
        inner: _Inner<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    struct _Inner<T>(Arc<T>);
    impl<T: StreamingPipelineService> StreamingPipelineServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            let inner = _Inner(inner);
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>>
    for StreamingPipelineServiceServer<T>
    where
        T: StreamingPipelineService,
        B: Body + Send + 'static,
        B::Error: Into<StdError> + Send + 'static,
    {
        type Response = http::Response<tonic::body::BoxBody>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            let inner = self.inner.clone();
            match req.uri().path() {
                "/remotemedia.v1.StreamingPipelineService/StreamPipeline" => {
                    #[allow(non_camel_case_types)]
                    struct StreamPipelineSvc<T: StreamingPipelineService>(pub Arc<T>);
                    impl<
                        T: StreamingPipelineService,
                    > tonic::server::StreamingService<super::StreamRequest>
                    for StreamPipelineSvc<T> {
                        type Response = super::StreamResponse;
                        type ResponseStream = T::StreamPipelineStream;
                        type Future = BoxFuture<
                            tonic::Response<Self::ResponseStream>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<
                                tonic::Streaming<super::StreamRequest>,
                            >,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as StreamingPipelineService>::stream_pipeline(
                                        &inner,
                                        request,
                                    )
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = StreamPipelineSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.streaming(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        Ok(
                            http::Response::builder()
                                .status(200)
                                .header("grpc-status", "12")
                                .header("content-type", "application/grpc")
                                .body(empty_body())
                                .unwrap(),
                        )
                    })
                }
            }
        }
    }
    impl<T: StreamingPipelineService> Clone for StreamingPipelineServiceServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    impl<T: StreamingPipelineService> Clone for _Inner<T> {
        fn clone(&self) -> Self {
            Self(Arc::clone(&self.0))
        }
    }
    impl<T: std::fmt::Debug> std::fmt::Debug for _Inner<T> {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            write!(f, "{:?}", self.0)
        }
    }
    impl<T: StreamingPipelineService> tonic::server::NamedService
    for StreamingPipelineServiceServer<T> {
        const NAME: &'static str = "remotemedia.v1.StreamingPipelineService";
    }
}
