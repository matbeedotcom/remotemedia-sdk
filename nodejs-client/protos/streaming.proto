// Bidirectional streaming pipeline execution RPC
// Feature: 003-rust-grpc-service
// 
// This file defines the StreamPipeline RPC for real-time streaming execution.
// Client and server exchange messages over persistent connection, enabling
// low-latency chunk-by-chunk processing.
//
// Use this RPC for:
// - Real-time audio processing (live transcription, VAD)
// - Interactive audio effects
// - Latency-sensitive applications (<50ms per chunk)

syntax = "proto3";

package remotemedia.v1;

import "common.proto";
import "execution.proto";

// ============================================================================
// Streaming Pipeline Service
// ============================================================================

service StreamingPipelineService {
  // Execute a pipeline with streaming audio input/output
  //
  // This is a bidirectional streaming RPC:
  // - Client sends: pipeline manifest (first message), then audio chunks
  // - Server sends: ready confirmation, then processing results per chunk
  //
  // Connection lifecycle:
  // 1. Client sends manifest → Server validates and responds with StreamReady
  // 2. Client sends audio chunks → Server processes and responds with results
  // 3. Client sends StreamControl::CLOSE → Server sends final metrics and closes
  //
  // Performance targets:
  // - <50ms average latency per chunk (User Story 3)
  // - Support 1000+ concurrent streaming sessions (SC-002)
  rpc StreamPipeline(stream StreamRequest) returns (stream StreamResponse);
}

// ============================================================================
// Request Types (Client → Server)
// ============================================================================

// Client streaming request
message StreamRequest {
  // Request type (only one field set per message)
  oneof request {
    // First message: pipeline initialization
    // Must be sent before any audio chunks
    StreamInit init = 1;

    // Subsequent messages: audio data chunks
    AudioChunk audio_chunk = 2;

    // Control commands (close, cancel)
    StreamControl control = 3;
  }
}

// Initialize streaming pipeline (first message)
message StreamInit {
  // Pipeline manifest
  PipelineManifest manifest = 1;

  // Initial non-audio inputs (JSON encoded, keyed by node ID)
  map<string, string> data_inputs = 2;

  // Optional resource limits
  ResourceLimits resource_limits = 3;

  // Client protocol version
  string client_version = 4;

  // Expected chunk size (samples per chunk)
  // Helps service optimize buffer allocation
  uint64 expected_chunk_size = 5;
}

// Audio data chunk
message AudioChunk {
  // Node ID to send this chunk to
  // Must match a node in the manifest that accepts streaming input
  string node_id = 1;

  // Audio data for this chunk
  AudioBuffer buffer = 2;

  // Sequence number for ordering
  // Client increments for each chunk (0, 1, 2, ...)
  // Server uses this to detect out-of-order or missing chunks
  uint64 sequence = 3;

  // Timestamp (milliseconds since stream start)
  // Optional, used for synchronization in multi-stream scenarios
  uint64 timestamp_ms = 4;
}

// Stream control commands
message StreamControl {
  // Control command type
  Command command = 1;

  // Control command enumeration
  enum Command {
    COMMAND_UNSPECIFIED = 0;

    // Graceful close: flush pending chunks, return final results
    COMMAND_CLOSE = 1;

    // Abort execution: cancel immediately, discard pending data
    COMMAND_CANCEL = 2;
  }
}

// ============================================================================
// Response Types (Server → Client)
// ============================================================================

// Server streaming response
message StreamResponse {
  // Response type (only one field set per message)
  oneof response {
    // First response: pipeline ready to receive chunks
    StreamReady ready = 1;

    // Processed chunk result (one per input chunk)
    ChunkResult result = 2;

    // Error occurred during streaming
    ErrorResponse error = 3;

    // Periodic metrics update
    StreamMetrics metrics = 4;

    // Stream closed gracefully
    StreamClosed closed = 5;
  }
}

// Pipeline initialized and ready to receive chunks
message StreamReady {
  // Unique session ID for this stream
  // Client can use for correlation in logs
  string session_id = 1;

  // Server-recommended chunk size (samples)
  // May differ from client's expected_chunk_size
  uint64 recommended_chunk_size = 2;

  // Maximum buffer latency (milliseconds)
  // Server will buffer up to this duration before processing
  uint64 max_buffer_latency_ms = 3;
}

// Result from processing a single chunk
message ChunkResult {
  // Sequence number (matches input AudioChunk.sequence)
  uint64 sequence = 1;

  // Processed audio outputs (keyed by node ID)
  map<string, AudioBuffer> audio_outputs = 2;

  // Non-audio outputs (JSON, keyed by node ID)
  // Example: VAD result: {"has_speech": true, "confidence": 0.87}
  map<string, string> data_outputs = 3;

  // Processing latency for this chunk (milliseconds)
  // Measured from chunk receipt to result ready
  double processing_time_ms = 4;

  // Cumulative samples processed in this stream
  uint64 total_samples_processed = 5;
}

// Periodic metrics update
//
// Server sends these periodically (e.g., every 10 chunks) to provide
// real-time visibility into stream health.
message StreamMetrics {
  // Session ID
  string session_id = 1;

  // Total chunks processed so far
  uint64 chunks_processed = 2;

  // Average latency across all chunks (milliseconds)
  double average_latency_ms = 3;

  // Total samples processed across all chunks
  uint64 total_samples = 4;

  // Current buffer occupancy (samples)
  uint64 buffer_samples = 5;

  // Number of chunks dropped (if any)
  uint64 chunks_dropped = 6;

  // Peak memory usage for this stream (bytes)
  uint64 peak_memory_bytes = 7;
}

// Stream closed gracefully
message StreamClosed {
  // Session ID
  string session_id = 1;

  // Final execution metrics
  ExecutionMetrics final_metrics = 2;

  // Reason for closure
  string reason = 3;
}

// ============================================================================
// Error Scenarios
// ============================================================================

// Streaming-specific error types
enum StreamErrorType {
  STREAM_ERROR_UNSPECIFIED = 0;

  // Manifest not sent as first message
  STREAM_ERROR_INIT_REQUIRED = 1;

  // Invalid chunk sequence (gap or out-of-order)
  STREAM_ERROR_INVALID_SEQUENCE = 2;

  // Buffer overflow (client sending faster than server can process)
  STREAM_ERROR_BUFFER_OVERFLOW = 3;

  // Stream timeout (no chunks received for X seconds)
  STREAM_ERROR_TIMEOUT = 4;

  // Client disconnected unexpectedly
  STREAM_ERROR_CLIENT_DISCONNECT = 5;

  // Pipeline execution error during chunk processing
  STREAM_ERROR_EXECUTION = 6;
}

// Extended error response for streaming
message StreamErrorResponse {
  // Base error information
  ErrorResponse base_error = 1;

  // Streaming-specific error type
  StreamErrorType stream_error_type = 2;

  // Sequence number where error occurred (if applicable)
  uint64 failing_sequence = 3;

  // Session ID
  string session_id = 4;
}
